{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1: Inputs & Parsing (Baseline Implementation)"
      ],
      "metadata": {
        "id": "gRxednLkRcA2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kZUcF4-Uf68I"
      },
      "outputs": [],
      "source": [
        "# Install PDF parsing library\n",
        "!pip install pymupdf pdfplumber"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import fitz  # PyMuPDF\n",
        "import pdfplumber\n",
        "import os"
      ],
      "metadata": {
        "id": "GoJIy79yRWR-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PDF Loader (baseline: PyMuPDF)\n",
        "def extract_text_pdf(path):\n",
        "    \"\"\"Extract text from a PDF file using PyMuPDF (fitz).\"\"\"\n",
        "    text = \"\"\n",
        "    with fitz.open(path) as doc:\n",
        "        for page in doc:\n",
        "            text += page.get_text(\"text\") + \"\\n\"\n",
        "    return text.strip()\n",
        "\n",
        "# Alternative: pdfplumber (can test later for accuracy)\n",
        "def extract_text_pdf_plumber(path):\n",
        "    \"\"\"Extract text using pdfplumber (slower but sometimes cleaner).\"\"\"\n",
        "    text = \"\"\n",
        "    with pdfplumber.open(path) as pdf:\n",
        "        for page in pdf.pages:\n",
        "            text += page.extract_text() + \"\\n\"\n",
        "    return text.strip()\n",
        "\n",
        "\n",
        "#TXT Loader\n",
        "def extract_text_txt(path):\n",
        "    \"\"\"Extract text from a plain .txt file.\"\"\"\n",
        "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "        return f.read().strip()\n",
        "\n",
        "\n",
        "# Unified Loader\n",
        "def load_documents(paths):\n",
        "    \"\"\"\n",
        "    Given a list of file paths (PDF or TXT), return a dict {filename: text}.\n",
        "    \"\"\"\n",
        "    docs = {}\n",
        "    for path in paths:\n",
        "        ext = os.path.splitext(path)[1].lower()\n",
        "        if ext == \".pdf\":\n",
        "            docs[path] = extract_text_pdf(path)\n",
        "        elif ext == \".txt\":\n",
        "            docs[path] = extract_text_txt(path)\n",
        "        else:\n",
        "            print(f\"‚ö†Ô∏è Skipping unsupported file type: {path}\")\n",
        "    return docs"
      ],
      "metadata": {
        "id": "xSUgMCjQRmMT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test Run\n",
        "paths = [\n",
        "    \"/content/notes.pdf\",\n",
        "    \"/content/transcript_1.txt\",\n",
        "    \"/content/transcript_2.txt\",\n",
        "    \"/content/transcript_3.txt\",\n",
        "    \"/content/transcript_4.txt\",\n",
        "    \"/content/transcript_5.txt\"\n",
        "]\n",
        "\n",
        "docs = load_documents(paths)\n",
        "\n",
        "# quick summary of extraction quality\n",
        "for name, text in docs.items():\n",
        "    print(\"=\"*80)\n",
        "    print(f\"üìÑ {name}\")\n",
        "    print(f\"Length (chars): {len(text)} | Length (words): {len(text.split())}\")\n",
        "    print(f\"Preview:\\n{text[:500]} ...\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hgxNbBLoRrEG",
        "outputId": "d0192f60-a232-43f6-923c-4c0c5fcff8a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "üìÑ /content/notes.pdf\n",
            "Length (chars): 288481 | Length (words): 60325\n",
            "Preview:\n",
            "Contents\n",
            "1\n",
            "Mathematical Preliminaries\n",
            "2\n",
            "1.1\n",
            "Trigonometric Identities . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
            "3\n",
            "1.2\n",
            "Magnitude and Angle Representation . . . . . . . . . . . . . . . . . . . . . .\n",
            "3\n",
            "1.3\n",
            "Complex Numbers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
            "4\n",
            "1.3.1\n",
            "History - (Veritasium‚Äôs video, KRN‚Äôs video) . . . . . . . . . . . . . .\n",
            "4\n",
            "1.3.2\n",
            "Cartesian Form - (Video, Python notebook) . . . . . . . . . . . . . .\n",
            "4\n",
            "1.3.3\n",
            "Magnitude and Phase (Video) . . . .  ...\n",
            "\n",
            "================================================================================\n",
            "üìÑ /content/transcript_1.txt\n",
            "Length (chars): 3537 | Length (words): 755\n",
            "Preview:\n",
            "we're going to quickly talk about  functions of a complex variable  and suppose z is a complex number  or z say it's a it's a complex variable  we say that f of z  is a function of z  if  f of z takes a unique value for a given  z in other words for one value of z  you cannot have two different values of  f of z  if that's the case you have only one  value of f of z for a given z then we  say that f of z is a function of a  complex variable  so there are many files i'll give you a  few examples  ...\n",
            "\n",
            "================================================================================\n",
            "üìÑ /content/transcript_2.txt\n",
            "Length (chars): 10542 | Length (words): 2095\n",
            "Preview:\n",
            "in this video i'm going to talk about  what is called as euler's formula  this is perhaps one of the most used  formulas in this course  and it's one of the most useful formulas  when dealing with complex numbers  and the formula essentially says  that  if you take a complex number of the form  cosine theta plus j times sine theta  this  can be thought of  as  e to the j times theta  now i'm going to go ahead and prove this  but before i go ahead and do the proof i  want to talk a little bit abo ...\n",
            "\n",
            "================================================================================\n",
            "üìÑ /content/transcript_3.txt\n",
            "Length (chars): 5496 | Length (words): 1115\n",
            "Preview:\n",
            "i'm going to quickly talk about how to  do arithmetic with complex numbers such  as how to  add two complex numbers subtract complex  numbers multiply divide  two complex numbers  it's this one is fairly easy you may  have seen this before but let's say we  have two complex numbers z1  which is a plus  sorry a1 plus j times b1  and z2  is a2 plus j times b2 and let's say  that's the cartesian representation for  z  and let's say we also have the polar  representation for z  as r1 times e to the  ...\n",
            "\n",
            "================================================================================\n",
            "üìÑ /content/transcript_4.txt\n",
            "Length (chars): 4921 | Length (words): 980\n",
            "Preview:\n",
            "have you ever wondered  why  roots of polynomials  with the real coefficients  always occur in conjugate pairs  well if you're probably not notice this  let's start with  the so the roots of a quadratic equation  let's say that you have a quadratic  equation x squared minus 2x plus 5 is  equal to 0  what are the roots of this quadratic  equation well you know that the two  roots  are  minus b plus square root of b squared  minus 4az over 2a and minus b minus  square root of b squared minus 4ac o ...\n",
            "\n",
            "================================================================================\n",
            "üìÑ /content/transcript_5.txt\n",
            "Length (chars): 36000 | Length (words): 6076\n",
            "Preview:\n",
            "Substituting some shooting frozen RNN,\\nbut when does the clock\\nokay.\\nLet's start.\\nOkay. So yes.\\nWe will indeed discusses and 31 for today.\\nI'm not an and is traveling for an academy Conference.\\nHe's giving a keynote.\\nHe's a keynote speaker and important conference.\\nSo he, he's not here today.\\nAnd he asked me if I can cover this class for him happily.\\nSome of you know me and the right,\\nfor others, My name is delete kiloton.\\nI'm an Associate Professor in the Departments.\\nMy research  ...\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Analyzing the output step-by-step:\n",
        "\n",
        "---\n",
        "\n",
        "### What is working:\n",
        "\n",
        "* **notes.pdf** ‚Üí \\~60k words captured (plenty of content). The preview shows **table of contents & headings** are preserved, which is good for chunking.\n",
        "* **Transcripts 1‚Äì5** ‚Üí All loaded fine, word counts make sense, text is readable. Even **transcript\\_5.txt** (longest, \\~6k words) extracted smoothly.\n",
        "* **Encoding** issues didn‚Äôt show up ‚Äî everything is UTF-8 clean.\n",
        "\n",
        "---\n",
        "\n",
        "### Needs improvement\n",
        "\n",
        "* **PDF artifacts**:\n",
        "\n",
        "  * `notes.pdf` output includes page numbers and dotted leader lines (`... . . . . .`).\n",
        "  * Likely to produce **noise in questions** if left uncleaned.\n",
        "\n",
        "* **Transcript artifacts**:\n",
        "\n",
        "  * Some repetition of filler speech (‚Äúokay‚Äù, ‚Äúlet‚Äôs start‚Äù).\n",
        "  * Transcript\\_5 has **line breaks (`\\n`) mid-sentence**.\n",
        "\n",
        "* **Uniformity**: Documents differ in style (formal textbook vs spoken transcript). Cleaning must normalize them before chunking.\n",
        "\n",
        "---\n",
        "\n",
        "### Step 1 Evaluation Metric\n",
        "\n",
        "Since we‚Äôre doing iterative improvements, let‚Äôs define a metric to **decide if cleaning helps**:\n",
        "\n",
        "1. **Text density** ‚Üí ratio of non-stopword tokens to total tokens. (Low ratio = too many ‚Äú. . .‚Äù or filler words).\n",
        "2. **Average sentence length** ‚Üí if too short (<5 words), text is broken; if too long (>50 words), sentences may be glued.\n",
        "3. **Compression ratio** ‚Üí compare length before vs. after cleaning. If we cut >10‚Äì15% junk without losing content, it‚Äôs good.\n",
        "\n",
        "---\n",
        "\n",
        "### Next Step (Baseline Cleaning Function)\n",
        "\n",
        "We can implement a **light cleaning pass**:\n",
        "\n",
        "* Remove page numbers & dotted lines.\n",
        "* Collapse multiple spaces ‚Üí one.\n",
        "* Merge broken lines ‚Üí sentences.\n",
        "* Strip filler tokens (‚Äúokay‚Äù, ‚Äúlet‚Äôs start‚Äù) only from transcripts.\n"
      ],
      "metadata": {
        "id": "Gr1EvauDRr9L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import nltk\n",
        "nltk.download(\"punkt\")\n",
        "\n",
        "def clean_text(text, is_transcript=False):\n",
        "    # Remove dotted leaders (from PDFs)\n",
        "    text = re.sub(r\"\\.{2,}\", \" \", text)\n",
        "\n",
        "    # Remove standalone page numbers\n",
        "    text = re.sub(r\"\\n\\d+\\n\", \"\\n\", text)\n",
        "\n",
        "    # Normalize whitespace\n",
        "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
        "\n",
        "    if is_transcript:\n",
        "        # Remove common fillers\n",
        "        fillers = [\"okay\", \"so yes\", \"let's start\", \"uh\", \"um\"]\n",
        "        for f in fillers:\n",
        "            text = re.sub(rf\"\\b{f}\\b\", \"\", text, flags=re.IGNORECASE)\n",
        "\n",
        "    return text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pzFYBxkpSBzX",
        "outputId": "ab972048-012d-4fed-80d4-a3dce53e952b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply cleaning\n",
        "docs_cleaned = {}\n",
        "for name, text in docs.items():\n",
        "    is_transcript = name.endswith(\".txt\")\n",
        "    docs_cleaned[name] = clean_text(text, is_transcript=is_transcript)\n",
        "\n",
        "# Quick preview after cleaning\n",
        "for name, text in docs_cleaned.items():\n",
        "    print(\"=\"*80)\n",
        "    print(f\"üìÑ Cleaned {name} | Length (words): {len(text.split())}\")\n",
        "    print(f\"Preview:\\n{text[:500]} ...\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vd9tLjbSSZHU",
        "outputId": "de80fafd-1467-404c-eff5-488b984661f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "üìÑ Cleaned /content/notes.pdf | Length (words): 58530\n",
            "Preview:\n",
            "Contents Mathematical Preliminaries 1.1 Trigonometric Identities . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1.2 Magnitude and Angle Representation . . . . . . . . . . . . . . . . . . . . . . 1.3 Complex Numbers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1.3.1 History - (Veritasium‚Äôs video, KRN‚Äôs video) . . . . . . . . . . . . . . 1.3.2 Cartesian Form - (Video, Python notebook) . . . . . . . . . . . . . . 1.3.3 Magnitude and Phase (Video) . . . . . . . . . . .  ...\n",
            "\n",
            "================================================================================\n",
            "üìÑ Cleaned /content/transcript_1.txt | Length (words): 753\n",
            "Preview:\n",
            "we're going to quickly talk about functions of a complex variable and suppose z is a complex number or z say it's a it's a complex variable we say that f of z is a function of z if f of z takes a unique value for a given z in other words for one value of z you cannot have two different values of f of z if that's the case you have only one value of f of z for a given z then we say that f of z is a function of a complex variable so there are many files i'll give you a few examples of functions tha ...\n",
            "\n",
            "================================================================================\n",
            "üìÑ Cleaned /content/transcript_2.txt | Length (words): 2088\n",
            "Preview:\n",
            "in this video i'm going to talk about what is called as euler's formula this is perhaps one of the most used formulas in this course and it's one of the most useful formulas when dealing with complex numbers and the formula essentially says that if you take a complex number of the form cosine theta plus j times sine theta this can be thought of as e to the j times theta now i'm going to go ahead and prove this but before i go ahead and do the proof i want to talk a little bit about how you are g ...\n",
            "\n",
            "================================================================================\n",
            "üìÑ Cleaned /content/transcript_3.txt | Length (words): 1111\n",
            "Preview:\n",
            "i'm going to quickly talk about how to do arithmetic with complex numbers such as how to add two complex numbers subtract complex numbers multiply divide two complex numbers it's this one is fairly easy you may have seen this before but let's say we have two complex numbers z1 which is a plus sorry a1 plus j times b1 and z2 is a2 plus j times b2 and let's say that's the cartesian representation for z and let's say we also have the polar representation for z as r1 times e to the j theta 1. and le ...\n",
            "\n",
            "================================================================================\n",
            "üìÑ Cleaned /content/transcript_4.txt | Length (words): 973\n",
            "Preview:\n",
            "have you ever wondered why roots of polynomials with the real coefficients always occur in conjugate pairs well if you're probably not notice this  with the so the roots of a quadratic equation let's say that you have a quadratic equation x squared minus 2x plus 5 is equal to 0 what are the roots of this quadratic equation well you know that the two roots are minus b plus square root of b squared minus 4az over 2a and minus b minus square root of b squared minus 4ac over 2a right and you notice  ...\n",
            "\n",
            "================================================================================\n",
            "üìÑ Cleaned /content/transcript_5.txt | Length (words): 6075\n",
            "Preview:\n",
            "Substituting some shooting frozen RNN,\\nbut when does the clock\\nokay.\\nLet's start.\\nOkay. .\\nWe will indeed discusses and 31 for today.\\nI'm not an and is traveling for an academy Conference.\\nHe's giving a keynote.\\nHe's a keynote speaker and important conference.\\nSo he, he's not here today.\\nAnd he asked me if I can cover this class for him happily.\\nSome of you know me and the right,\\nfor others, My name is delete kiloton.\\nI'm an Associate Professor in the Departments.\\nMy research area i ...\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Improvements\n",
        "\n",
        "* **Page numbers** are mostly gone.\n",
        "* **Transcript line breaks** are collapsed ‚Üí sentences flow better (compare transcript\\_1 and transcript\\_2 before vs. after).\n",
        "* Word counts barely dropped (e.g., `notes.pdf` 60,325 ‚Üí 58,530), meaning we removed junk while preserving content.\n",
        "* Filler removal worked moderately (short transcripts look smoother).\n",
        "\n",
        "---\n",
        "\n",
        "### Remaining issues\n",
        "\n",
        "* **PDF table of contents** still has dotted leaders (`. . . . .`). My regex didn‚Äôt catch ‚Äúspace-dot-space‚Äù patterns.\n",
        "* **Transcript\\_5** still has some speech artifacts (`okay`, broken lines with `\\n`). Needs stronger cleanup for spoken filler.\n",
        "* **Sentence boundaries**: All text is one long string right now. For chunking later, we‚Äôll want clean **sentence segmentation** (using `nltk.sent_tokenize` or `spacy`).\n",
        "\n",
        "---\n",
        "\n",
        "### Let‚Äôs Quantify Cleaning\n",
        "\n",
        "We are testing improvements with metrics, here are the checks we should add:\n",
        "\n",
        "1. **Compression ratio** ‚Üí `(len(raw_text) - len(cleaned_text)) / len(raw_text)`\n",
        "\n",
        "   * Tells us % junk removed.\n",
        "2. **Average sentence length** ‚Üí `avg_words_per_sentence`\n",
        "\n",
        "   * Too short ‚Üí broken lines; too long ‚Üí glued text.\n",
        "3. **Lexical density** ‚Üí ratio of non-stopwords to total words.\n",
        "\n",
        "   * Low density ‚Üí still noisy.\n"
      ],
      "metadata": {
        "id": "HXidQUBFSfGJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import nltk\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "\n",
        "# Download all needed resources\n",
        "nltk.download(\"punkt\")\n",
        "nltk.download(\"punkt_tab\")\n",
        "nltk.download(\"stopwords\")\n",
        "\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "stop_words = set(stopwords.words(\"english\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JOTSjkPYTREu",
        "outputId": "9fea4428-ecf1-4b00-8111-c4ab3a24870b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(raw_text, cleaned_text):\n",
        "    # Compression ratio\n",
        "    comp_ratio = (len(raw_text) - len(cleaned_text)) / max(1, len(raw_text))\n",
        "\n",
        "    # Sentence stats (after cleaning)\n",
        "    sentences = sent_tokenize(cleaned_text)\n",
        "    if sentences:\n",
        "        avg_sent_len = np.mean([len(word_tokenize(s)) for s in sentences])\n",
        "    else:\n",
        "        avg_sent_len = 0\n",
        "\n",
        "    # Lexical density (after cleaning)\n",
        "    words = word_tokenize(cleaned_text.lower())\n",
        "    if words:\n",
        "        non_stopwords = [w for w in words if w.isalpha() and w not in stop_words]\n",
        "        lexical_density = len(non_stopwords) / len(words)\n",
        "    else:\n",
        "        lexical_density = 0\n",
        "\n",
        "    return {\n",
        "        \"compression_ratio\": round(comp_ratio, 4),\n",
        "        \"avg_sentence_length\": round(avg_sent_len, 2),\n",
        "        \"lexical_density\": round(lexical_density, 3),\n",
        "        \"num_sentences\": len(sentences),\n",
        "        \"num_words\": len(words),\n",
        "    }\n",
        "\n",
        "# Compare raw vs cleaned for all docs\n",
        "metrics_results = {}\n",
        "for name in docs:\n",
        "    metrics_results[name] = compute_metrics(docs[name], docs_cleaned[name])"
      ],
      "metadata": {
        "id": "7641aFgJTTio"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df_metrics = pd.DataFrame(metrics_results).T\n",
        "df_metrics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "-K0MkuirTWHC",
        "outputId": "11a5e959-96f2-4152-af52-551eba1a4c4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                           compression_ratio  avg_sentence_length  \\\n",
              "/content/notes.pdf                    0.0150                12.46   \n",
              "/content/transcript_1.txt             0.0370               769.00   \n",
              "/content/transcript_2.txt             0.0361              2151.00   \n",
              "/content/transcript_3.txt             0.0402              1134.00   \n",
              "/content/transcript_4.txt             0.0445               997.00   \n",
              "/content/transcript_5.txt             0.0017               104.37   \n",
              "\n",
              "                           lexical_density  num_sentences  num_words  \n",
              "/content/notes.pdf                   0.305         6555.0    81060.0  \n",
              "/content/transcript_1.txt            0.428            1.0      769.0  \n",
              "/content/transcript_2.txt            0.482            1.0     2151.0  \n",
              "/content/transcript_3.txt            0.436            1.0     1134.0  \n",
              "/content/transcript_4.txt            0.411            1.0      997.0  \n",
              "/content/transcript_5.txt            0.367           67.0     6993.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b884fd54-00ce-4749-82d3-bdc9104b8bf3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>compression_ratio</th>\n",
              "      <th>avg_sentence_length</th>\n",
              "      <th>lexical_density</th>\n",
              "      <th>num_sentences</th>\n",
              "      <th>num_words</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>/content/notes.pdf</th>\n",
              "      <td>0.0150</td>\n",
              "      <td>12.46</td>\n",
              "      <td>0.305</td>\n",
              "      <td>6555.0</td>\n",
              "      <td>81060.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>/content/transcript_1.txt</th>\n",
              "      <td>0.0370</td>\n",
              "      <td>769.00</td>\n",
              "      <td>0.428</td>\n",
              "      <td>1.0</td>\n",
              "      <td>769.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>/content/transcript_2.txt</th>\n",
              "      <td>0.0361</td>\n",
              "      <td>2151.00</td>\n",
              "      <td>0.482</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2151.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>/content/transcript_3.txt</th>\n",
              "      <td>0.0402</td>\n",
              "      <td>1134.00</td>\n",
              "      <td>0.436</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1134.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>/content/transcript_4.txt</th>\n",
              "      <td>0.0445</td>\n",
              "      <td>997.00</td>\n",
              "      <td>0.411</td>\n",
              "      <td>1.0</td>\n",
              "      <td>997.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>/content/transcript_5.txt</th>\n",
              "      <td>0.0017</td>\n",
              "      <td>104.37</td>\n",
              "      <td>0.367</td>\n",
              "      <td>67.0</td>\n",
              "      <td>6993.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b884fd54-00ce-4749-82d3-bdc9104b8bf3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b884fd54-00ce-4749-82d3-bdc9104b8bf3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b884fd54-00ce-4749-82d3-bdc9104b8bf3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-7d973342-b7ca-4946-9222-67f0d978d0b5\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7d973342-b7ca-4946-9222-67f0d978d0b5')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-7d973342-b7ca-4946-9222-67f0d978d0b5 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_9cdaea8e-e242-492f-8a4e-66c609001643\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_metrics')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_9cdaea8e-e242-492f-8a4e-66c609001643 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_metrics');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_metrics",
              "summary": "{\n  \"name\": \"df_metrics\",\n  \"rows\": 6,\n  \"fields\": [\n    {\n      \"column\": \"compression_ratio\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.016860298534328112,\n        \"min\": 0.0017,\n        \"max\": 0.0445,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.015,\n          0.037,\n          0.0017\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"avg_sentence_length\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 782.061062878085,\n        \"min\": 12.46,\n        \"max\": 2151.0,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          12.46,\n          769.0,\n          104.37\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lexical_density\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.06147980698299781,\n        \"min\": 0.305,\n        \"max\": 0.482,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.305,\n          0.428,\n          0.367\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"num_sentences\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2670.400918713643,\n        \"min\": 1.0,\n        \"max\": 6555.0,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          6555.0,\n          1.0,\n          67.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"num_words\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 32194.40315748479,\n        \"min\": 769.0,\n        \"max\": 81060.0,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          81060.0,\n          769.0,\n          6993.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Interpretation of Metrics\n",
        "\n",
        "**1. Compression ratio**\n",
        "\n",
        "* **notes.pdf ‚Üí 0.015** (1.5%) ‚Üí Very little junk removed. That‚Äôs fine, since it‚Äôs a structured textbook-style doc.\n",
        "* **transcripts 1‚Äì4 ‚Üí \\~0.037‚Äì0.045 (3‚Äì4.5%)** ‚Üí We did cut some filler, but not much.\n",
        "* **transcript\\_5 ‚Üí 0.0017 (0.17%)** ‚Üí Almost no cleaning effect. Likely lots of irregular text still present.\n",
        "\n",
        "**2. Average sentence length**\n",
        "\n",
        "* **notes.pdf ‚Üí 12.5 words** ‚Üí Perfect range (normal prose).\n",
        "* **transcripts 1‚Äì4 ‚Üí insane values (769‚Äì2151 words per ‚Äúsentence‚Äù)** ‚Üí This means our tokenizer only found **1 giant ‚Äúsentence‚Äù** per file. Line breaks weren‚Äôt interpreted as sentence boundaries.\n",
        "* **transcript\\_5 ‚Üí 104 words** ‚Üí Better than the others, but still too long.\n",
        "\n",
        "**3. Lexical density**\n",
        "\n",
        "* **notes.pdf ‚Üí 0.305** (low!) ‚Üí Suggests a lot of stopwords, possibly due to table-of-contents dots, repeated formatting junk.\n",
        "* **transcripts 1‚Äì4 ‚Üí \\~0.41‚Äì0.48** ‚Üí More natural density, good for speech-like text.\n",
        "* **transcript\\_5 ‚Üí 0.367** ‚Üí A bit noisy; still cluttered with filler speech.\n",
        "\n",
        "**4. Sentence counts**\n",
        "\n",
        "* **notes.pdf ‚Üí 6,555 sentences** (reasonable).\n",
        "* **transcripts 1‚Äì4 ‚Üí only 1 sentence each** ‚Üí Major problem ‚Äî need better sentence segmentation.\n",
        "* **transcript\\_5 ‚Üí 67 sentences** ‚Üí Better, but still not natural given 7k words.\n",
        "\n",
        "---\n",
        "\n",
        "### Conclusion\n",
        "\n",
        "* **notes.pdf is fine** (maybe improve lexical density by stripping table-of-contents junk).\n",
        "* **Transcripts 1‚Äì4 are NOT fine** ‚Äî they look like one giant blob. Sentence tokenizer failed because transcripts lack punctuation (`.`, `?`, `!`).\n",
        "* **transcript\\_5 is partially okay** but still chunky.\n",
        "\n",
        "---\n",
        "\n",
        "### Potential Fix\n",
        "\n",
        "For transcripts, we need a **custom sentence splitter**:\n",
        "\n",
        "1. Use `.` `?` `!` as usual.\n",
        "2. Also split on **long pauses/line breaks** (`\\n`) even without punctuation.\n",
        "3. Add heuristic: if a line >50 words with no punctuation ‚Üí break it artificially every \\~20‚Äì30 words."
      ],
      "metadata": {
        "id": "OOJzj7zOTXGA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !cat /content/transcript_2.txt"
      ],
      "metadata": {
        "id": "wGo89yU1T5Ee"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After seeing the **raw structure** of these documents:\n",
        "\n",
        "* **Transcript\\_1‚Äì4** ‚Üí continuous spoken explanations, minimal punctuation, mostly line breaks. That‚Äôs why NLTK thought each file was **one giant sentence**.\n",
        "* **Transcript\\_5** ‚Üí still lecture-style, but with more `\\n` line breaks and some punctuation, so it segmented into \\~67 sentences.\n",
        "\n",
        "---\n",
        "\n",
        "### Custom Segmentation\n",
        "\n",
        "To process these for downstream **chunking + question generation**, we need to create **synthetic sentence boundaries** that better reflect natural pauses in speech:\n",
        "\n",
        "1. **Split on explicit punctuation** (`.`, `?`, `!`) ‚Äî where it exists.\n",
        "2. **Fallback to line breaks** (`\\n`) when no punctuation.\n",
        "3. **Heuristic splitting of long runs**:\n",
        "\n",
        "   * If a segment > 40‚Äì50 words with no punctuation, break it into smaller ‚Äúpseudo-sentences‚Äù every \\~20‚Äì25 words.\n",
        "   * This avoids 1,000-word ‚Äúsentences‚Äù that blow up average length."
      ],
      "metadata": {
        "id": "ohQ8HVGEUdvS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def custom_transcript_segmenter(text, max_words_per_segment=25):\n",
        "    \"\"\"\n",
        "    Segment transcript text into smaller 'sentences' using punctuation,\n",
        "    line breaks, and word-count heuristics.\n",
        "    \"\"\"\n",
        "    # Normalize whitespace\n",
        "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
        "\n",
        "    # Step 1: Split on ., ?, !\n",
        "    rough_segments = re.split(r'(?<=[.?!])\\s+', text)\n",
        "\n",
        "    # Step 2: Also split on \\n if any remain\n",
        "    refined_segments = []\n",
        "    for seg in rough_segments:\n",
        "        refined_segments.extend(re.split(r\"\\n+\", seg))\n",
        "\n",
        "    # Step 3: Word-count based splitting\n",
        "    final_segments = []\n",
        "    for seg in refined_segments:\n",
        "        words = seg.strip().split()\n",
        "        if not words:\n",
        "            continue\n",
        "        if len(words) > max_words_per_segment:\n",
        "            # Break into chunks of max_words_per_segment\n",
        "            for i in range(0, len(words), max_words_per_segment):\n",
        "                final_segments.append(\" \".join(words[i:i+max_words_per_segment]))\n",
        "        else:\n",
        "            final_segments.append(seg.strip())\n",
        "\n",
        "    return final_segments"
      ],
      "metadata": {
        "id": "3vcUBcs7UkGG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply to transcripts\n",
        "segmented_transcripts = {}\n",
        "for name, text in docs_cleaned.items():\n",
        "    if name.endswith(\".txt\"):  # transcripts only\n",
        "        segs = custom_transcript_segmenter(text)\n",
        "        segmented_transcripts[name] = segs\n",
        "        print(\"=\"*80)\n",
        "        print(f\"üìÑ {name} | Segments: {len(segs)} | Avg words/segment: {sum(len(s.split()) for s in segs)/len(segs):.2f}\")\n",
        "        print(\"Sample segments:\")\n",
        "        for s in segs[:3]:\n",
        "            print(f\" - {s}\")\n",
        "        print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AwRK18V8U-Ha",
        "outputId": "564a28b1-7202-4de8-accf-22c89f808a5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "üìÑ /content/transcript_1.txt | Segments: 31 | Avg words/segment: 24.29\n",
            "Sample segments:\n",
            " - we're going to quickly talk about functions of a complex variable and suppose z is a complex number or z say it's a it's a\n",
            " - complex variable we say that f of z is a function of z if f of z takes a unique value for a given z\n",
            " - in other words for one value of z you cannot have two different values of f of z if that's the case you have only\n",
            "\n",
            "================================================================================\n",
            "üìÑ /content/transcript_2.txt | Segments: 86 | Avg words/segment: 24.28\n",
            "Sample segments:\n",
            " - in this video i'm going to talk about what is called as euler's formula this is perhaps one of the most used formulas in this\n",
            " - course and it's one of the most useful formulas when dealing with complex numbers and the formula essentially says that if you take a complex\n",
            " - number of the form cosine theta plus j times sine theta this can be thought of as e to the j times theta now i'm\n",
            "\n",
            "================================================================================\n",
            "üìÑ /content/transcript_3.txt | Segments: 46 | Avg words/segment: 24.15\n",
            "Sample segments:\n",
            " - i'm going to quickly talk about how to do arithmetic with complex numbers such as how to add two complex numbers subtract complex numbers multiply\n",
            " - divide two complex numbers it's this one is fairly easy you may have seen this before but let's say we have two complex numbers z1\n",
            " - which is a plus sorry a1 plus j times b1 and z2 is a2 plus j times b2 and let's say that's the cartesian representation\n",
            "\n",
            "================================================================================\n",
            "üìÑ /content/transcript_4.txt | Segments: 41 | Avg words/segment: 23.73\n",
            "Sample segments:\n",
            " - have you ever wondered why roots of polynomials with the real coefficients always occur in conjugate pairs well if you're probably not notice this with\n",
            " - the so the roots of a quadratic equation let's say that you have a quadratic equation x squared minus 2x plus 5 is equal to\n",
            " - 0 what are the roots of this quadratic equation well you know that the two roots are minus b plus square root of b squared\n",
            "\n",
            "================================================================================\n",
            "üìÑ /content/transcript_5.txt | Segments: 293 | Avg words/segment: 20.73\n",
            "Sample segments:\n",
            " - Substituting some shooting frozen RNN,\\nbut when does the clock\\nokay.\\nLet's start.\\nOkay.\n",
            " - .\\nWe will indeed discusses and 31 for today.\\nI'm not an and is traveling for an academy Conference.\\nHe's giving a keynote.\\nHe's a keynote speaker and important\n",
            " - conference.\\nSo he, he's not here today.\\nAnd he asked me if I can cover this class for him happily.\\nSome of you know me and the right,\\nfor\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What this achieves\n",
        "\n",
        "* Transcript\\_1‚Äì4 ‚Üí Instead of 1 huge sentence, you‚Äôll now get **dozens/hundreds of manageable segments** (\\~20 words each).\n",
        "* Transcript\\_5 ‚Üí Already somewhat segmented, but this will normalize lengths.\n",
        "* Keeps average segment length in the **10‚Äì25 word range**, which is ideal for chunking later."
      ],
      "metadata": {
        "id": "O1H4TAxcU2BW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "stop_words = set(stopwords.words(\"english\"))"
      ],
      "metadata": {
        "id": "2SFcfmj3U55q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics_segments(segments, raw_text):\n",
        "    # Compression ratio (still compare raw vs segmented-joined text)\n",
        "    joined = \" \".join(segments)\n",
        "    comp_ratio = (len(raw_text) - len(joined)) / max(1, len(raw_text))\n",
        "\n",
        "    # Average sentence length (using our segments)\n",
        "    if segments:\n",
        "        avg_sent_len = np.mean([len(word_tokenize(s)) for s in segments])\n",
        "    else:\n",
        "        avg_sent_len = 0\n",
        "\n",
        "    # Lexical density (words not in stopword list / total words)\n",
        "    words = word_tokenize(joined.lower())\n",
        "    if words:\n",
        "        non_stopwords = [w for w in words if w.isalpha() and w not in stop_words]\n",
        "        lexical_density = len(non_stopwords) / len(words)\n",
        "    else:\n",
        "        lexical_density = 0\n",
        "\n",
        "    return {\n",
        "        \"compression_ratio\": round(comp_ratio, 4),\n",
        "        \"avg_sentence_length\": round(avg_sent_len, 2),\n",
        "        \"lexical_density\": round(lexical_density, 3),\n",
        "        \"num_sentences\": len(segments),\n",
        "        \"num_words\": len(words),\n",
        "    }"
      ],
      "metadata": {
        "id": "50uCRlFbVRZs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute metrics again\n",
        "metrics_segments = {}\n",
        "for name in docs:\n",
        "    if name.endswith(\".txt\"):\n",
        "        segments = segmented_transcripts[name]\n",
        "        metrics_segments[name] = compute_metrics_segments(segments, docs[name])\n",
        "    else:\n",
        "        # notes.pdf ‚Üí fall back to original sentence tokenization\n",
        "        metrics_segments[name] = compute_metrics_segments(sent_tokenize(docs_cleaned[name]), docs[name])"
      ],
      "metadata": {
        "id": "gS7UfvHHVTfg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_metrics2 = pd.DataFrame(metrics_segments).T\n",
        "df_metrics2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "KwHHLGumVVAT",
        "outputId": "cacd6d97-9a4b-4422-f896-7d71a15e4eaf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                           compression_ratio  avg_sentence_length  \\\n",
              "/content/notes.pdf                    0.0149                12.46   \n",
              "/content/transcript_1.txt             0.0376                24.84   \n",
              "/content/transcript_2.txt             0.0368                25.06   \n",
              "/content/transcript_3.txt             0.0409                24.76   \n",
              "/content/transcript_4.txt             0.0457                24.39   \n",
              "/content/transcript_5.txt             0.0017                23.98   \n",
              "\n",
              "                           lexical_density  num_sentences  num_words  \n",
              "/content/notes.pdf                   0.305         6555.0    81060.0  \n",
              "/content/transcript_1.txt            0.428           31.0      769.0  \n",
              "/content/transcript_2.txt            0.482           86.0     2151.0  \n",
              "/content/transcript_3.txt            0.436           46.0     1134.0  \n",
              "/content/transcript_4.txt            0.411           41.0      997.0  \n",
              "/content/transcript_5.txt            0.367          293.0     6993.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-13aec9d8-d809-4f91-9093-bd07c05b6bbd\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>compression_ratio</th>\n",
              "      <th>avg_sentence_length</th>\n",
              "      <th>lexical_density</th>\n",
              "      <th>num_sentences</th>\n",
              "      <th>num_words</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>/content/notes.pdf</th>\n",
              "      <td>0.0149</td>\n",
              "      <td>12.46</td>\n",
              "      <td>0.305</td>\n",
              "      <td>6555.0</td>\n",
              "      <td>81060.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>/content/transcript_1.txt</th>\n",
              "      <td>0.0376</td>\n",
              "      <td>24.84</td>\n",
              "      <td>0.428</td>\n",
              "      <td>31.0</td>\n",
              "      <td>769.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>/content/transcript_2.txt</th>\n",
              "      <td>0.0368</td>\n",
              "      <td>25.06</td>\n",
              "      <td>0.482</td>\n",
              "      <td>86.0</td>\n",
              "      <td>2151.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>/content/transcript_3.txt</th>\n",
              "      <td>0.0409</td>\n",
              "      <td>24.76</td>\n",
              "      <td>0.436</td>\n",
              "      <td>46.0</td>\n",
              "      <td>1134.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>/content/transcript_4.txt</th>\n",
              "      <td>0.0457</td>\n",
              "      <td>24.39</td>\n",
              "      <td>0.411</td>\n",
              "      <td>41.0</td>\n",
              "      <td>997.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>/content/transcript_5.txt</th>\n",
              "      <td>0.0017</td>\n",
              "      <td>23.98</td>\n",
              "      <td>0.367</td>\n",
              "      <td>293.0</td>\n",
              "      <td>6993.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-13aec9d8-d809-4f91-9093-bd07c05b6bbd')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-13aec9d8-d809-4f91-9093-bd07c05b6bbd button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-13aec9d8-d809-4f91-9093-bd07c05b6bbd');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-55330e0b-1477-47e2-94ae-388ac6df8d8f\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-55330e0b-1477-47e2-94ae-388ac6df8d8f')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-55330e0b-1477-47e2-94ae-388ac6df8d8f button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_28090880-5ec0-4d9c-91f6-e7cda8f0d086\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_metrics2')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_28090880-5ec0-4d9c-91f6-e7cda8f0d086 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_metrics2');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_metrics2",
              "summary": "{\n  \"name\": \"df_metrics2\",\n  \"rows\": 6,\n  \"fields\": [\n    {\n      \"column\": \"compression_ratio\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.01730456587146872,\n        \"min\": 0.0017,\n        \"max\": 0.0457,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.0149,\n          0.0376,\n          0.0017\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"avg_sentence_length\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4.973145550520984,\n        \"min\": 12.46,\n        \"max\": 25.06,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          12.46,\n          24.84,\n          23.98\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lexical_density\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.06147980698299781,\n        \"min\": 0.305,\n        \"max\": 0.482,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.305,\n          0.428,\n          0.367\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"num_sentences\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2637.3311257152877,\n        \"min\": 31.0,\n        \"max\": 6555.0,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          6555.0,\n          31.0,\n          293.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"num_words\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 32194.40315748479,\n        \"min\": 769.0,\n        \"max\": 81060.0,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          81060.0,\n          769.0,\n          6993.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Interpretation of the new metrics\n",
        "\n",
        "**notes.pdf**\n",
        "\n",
        "* Avg sentence length \\~12 ‚Üí natural prose.\n",
        "* Lexical density low (\\~0.30) because of table of contents and math-heavy sections, but manageable.\n",
        "\n",
        "**Transcripts 1‚Äì4**\n",
        "\n",
        "* Avg sentence length \\~25 words (ideal for our use case).\n",
        "* Sentence counts: 31, 86, 46, 41 ‚Üí good granularity.\n",
        "* Lexical density \\~0.41‚Äì0.48 ‚Üí natural spoken technical content.\n",
        "\n",
        "**Transcript\\_5**\n",
        "\n",
        "* Avg sentence length \\~24 words.\n",
        "* Segment count 293 ‚Üí nicely chunked.\n",
        "* Lexical density \\~0.37 ‚Üí slightly noisy but fine.\n",
        "\n",
        "---\n",
        "\n",
        "### Conclusion\n",
        "\n",
        "Now, **all documents are in a comparable range**:\n",
        "\n",
        "* Sentence length: 12‚Äì25 words\n",
        "* Lexical density: 0.30‚Äì0.48\n",
        "* Sentence counts: balanced for chunking\n",
        "\n",
        "This means the preprocessing step (Step 1) is **done and validated**"
      ],
      "metadata": {
        "id": "kOtsuHG0VV8V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Step 2: Chunking**.\n",
        "We‚Äôll start with a **baseline chunker** that is:\n",
        "\n",
        "* **Section-aware** for `notes.pdf` (uses headings to reset chunks).\n",
        "* **Sentence-based** for transcripts (uses our segmented sentences).\n",
        "* Creates chunks of \\~300‚Äì500 words with \\~50-word overlap to preserve context.\n",
        "\n",
        "Later, we can test improvements (semantic chunking, adaptive sizes, etc.), but let‚Äôs start simple."
      ],
      "metadata": {
        "id": "il58x74kVmtD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from itertools import islice\n",
        "\n",
        "def sliding_window(sentences, chunk_size=400, stride=50):\n",
        "    \"\"\"\n",
        "    Yield overlapping chunks from a list of sentences.\n",
        "    Each chunk is approx chunk_size words, with stride overlap.\n",
        "    \"\"\"\n",
        "    words = []\n",
        "    for sent in sentences:\n",
        "        words.extend(sent.split())\n",
        "    chunks = []\n",
        "    start = 0\n",
        "    while start < len(words):\n",
        "        end = min(start + chunk_size, len(words))\n",
        "        chunk_words = words[start:end]\n",
        "        chunks.append(\" \".join(chunk_words))\n",
        "        if end == len(words):  # reached the end\n",
        "            break\n",
        "        start += (chunk_size - stride)\n",
        "    return chunks\n",
        "\n",
        "\n",
        "def split_sections_pdf(text):\n",
        "    \"\"\"\n",
        "    Rough section splitter for PDF notes.\n",
        "    Splits on numbered headings like 1.2, 2.1.3, or ALL CAPS headings.\n",
        "    \"\"\"\n",
        "    sections = re.split(r\"\\n(?=\\d+(\\.\\d+)*\\s+|[A-Z][A-Z\\s]{3,})\", text)\n",
        "    return [s.strip() for s in sections if len(s.strip()) > 50]\n",
        "\n",
        "\n",
        "def chunk_document(name, text, segmented_sentences=None, chunk_size=400, stride=50):\n",
        "    \"\"\"\n",
        "    Chunk either a PDF or a transcript into overlapping chunks.\n",
        "    - PDF: use section splitter, then sliding windows\n",
        "    - Transcript: use provided segmented sentences, then sliding windows\n",
        "    \"\"\"\n",
        "    all_chunks = []\n",
        "\n",
        "    if name.endswith(\".pdf\"):\n",
        "        sections = split_sections_pdf(text)\n",
        "        for sec in sections:\n",
        "            sec_chunks = sliding_window(sec.split(\". \"), chunk_size, stride)\n",
        "            for c in sec_chunks:\n",
        "                all_chunks.append({\n",
        "                    \"doc\": name,\n",
        "                    \"section\": sec[:50],  # preview of section heading\n",
        "                    \"text\": c\n",
        "                })\n",
        "\n",
        "    elif name.endswith(\".txt\") and segmented_sentences:\n",
        "        sec_chunks = sliding_window(segmented_sentences, chunk_size, stride)\n",
        "        for c in sec_chunks:\n",
        "            all_chunks.append({\n",
        "                \"doc\": name,\n",
        "                \"section\": \"transcript\",\n",
        "                \"text\": c\n",
        "            })\n",
        "    return all_chunks"
      ],
      "metadata": {
        "id": "aO85YJOLWIvE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test Run on notes.pdf and transcript_1.txt\n",
        "chunks_notes = chunk_document(\"/content/notes.pdf\", docs_cleaned[\"/content/notes.pdf\"])\n",
        "chunks_transcript1 = chunk_document(\"/content/transcript_1.txt\",\n",
        "                                    docs_cleaned[\"/content/transcript_1.txt\"],\n",
        "                                    segmented_transcripts[\"/content/transcript_1.txt\"])\n",
        "\n",
        "print(f\"üìÑ notes.pdf ‚Üí {len(chunks_notes)} chunks\")\n",
        "print(f\"üìÑ transcript_1.txt ‚Üí {len(chunks_transcript1)} chunks\")\n",
        "\n",
        "print(\"\\nSample note chunk:\\n\", chunks_notes[0][\"text\"][:500], \"...\")\n",
        "print(\"\\nSample transcript chunk:\\n\", chunks_transcript1[0][\"text\"][:500], \"...\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7WsgJsxLWM9D",
        "outputId": "fe29c0f0-45b7-400f-dedb-18668bb43ed5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÑ notes.pdf ‚Üí 156 chunks\n",
            "üìÑ transcript_1.txt ‚Üí 3 chunks\n",
            "\n",
            "Sample note chunk:\n",
            " Contents Mathematical Preliminaries 1.1 Trigonometric Identities 1.2 Magnitude and Angle Representation 1.3 Complex Numbers 1.3.1 History - (Veritasium‚Äôs video, KRN‚Äôs video) 1.3.2 Cartesian Form - (Video, Python notebook) 1.3.3 Magnitude and Phase (Video) 1.3.4 Euler‚Äôs Formula - (Video) 1.3.5 Polar form or Exponential form (Video) 1.3.6 Conjugate - (Video) 1.3.7 Arithmetic with two complex numbers - (Video) 1.3.8 Geometric interpretation of arithmetic operations - (Video, Python notebook) 1.3.9  ...\n",
            "\n",
            "Sample transcript chunk:\n",
            " we're going to quickly talk about functions of a complex variable and suppose z is a complex number or z say it's a it's a complex variable we say that f of z is a function of z if f of z takes a unique value for a given z in other words for one value of z you cannot have two different values of f of z if that's the case you have only one value of f of z for a given z then we say that f of z is a function of a complex variable so there are many files i'll give you a few examples of functions tha ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What this does\n",
        "\n",
        "\n",
        "* Splits **notes.pdf** into sections (using headings like `1.1`, `2.3.1`, etc.) then applies sliding window chunking.\n",
        "* Splits **transcripts** using our segmented sentences, then applies sliding window chunking.\n",
        "* Each chunk is \\~400 words with \\~50-word overlap.\n",
        "* Each chunk is stored with metadata `{doc, section, text}`."
      ],
      "metadata": {
        "id": "No3LFNumWRWY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Observations\n",
        "\n",
        "**notes.pdf**\n",
        "\n",
        "* 156 chunks ‚Üí looks right given \\~80k words.\n",
        "* Sample chunk is clean and section-based. Chunking seems healthy.\n",
        "\n",
        "**transcript\\_1.txt**\n",
        "\n",
        "* Only 3 chunks, despite 769 words split into 31 segments.\n",
        "* Why so few? ‚Üí Because our chunk size was **400 words**. With \\~750 total words, sliding window gave just 2‚Äì3 big chunks.\n",
        "\n",
        "---\n",
        "\n",
        "### Issue for Transcripts\n",
        "\n",
        "Transcripts are **shorter overall**, so they don‚Äôt need such large chunks.\n",
        "If we leave chunk size at 400 words, we get only a handful of chunks, which is too coarse for question generation.\n",
        "\n",
        "---\n",
        "\n",
        "### Fix\n",
        "\n",
        "Let‚Äôs make **chunk size adaptive**:\n",
        "\n",
        "* PDFs (long, dense) ‚Üí keep `chunk_size = 400` words.\n",
        "* Transcripts (short, segmented speech) ‚Üí smaller, `chunk_size = 150‚Äì200`, with `stride = 30`."
      ],
      "metadata": {
        "id": "TW47aRVHWU-K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def chunk_document_adaptive(name, text, segmented_sentences=None):\n",
        "    all_chunks = []\n",
        "\n",
        "    if name.endswith(\".pdf\"):\n",
        "        sections = split_sections_pdf(text)\n",
        "        for sec in sections:\n",
        "            sec_chunks = sliding_window(sec.split(\". \"), chunk_size=400, stride=50)\n",
        "            for c in sec_chunks:\n",
        "                all_chunks.append({\n",
        "                    \"doc\": name,\n",
        "                    \"section\": sec[:50],\n",
        "                    \"text\": c\n",
        "                })\n",
        "\n",
        "    elif name.endswith(\".txt\") and segmented_sentences:\n",
        "        # Smaller chunk size for transcripts\n",
        "        sec_chunks = sliding_window(segmented_sentences, chunk_size=180, stride=30)\n",
        "        for c in sec_chunks:\n",
        "            all_chunks.append({\n",
        "                \"doc\": name,\n",
        "                \"section\": \"transcript\",\n",
        "                \"text\": c\n",
        "            })\n",
        "    return all_chunks"
      ],
      "metadata": {
        "id": "0erln3gkWsvw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test adaptive chunking\n",
        "chunks_transcript1_adaptive = chunk_document_adaptive(\n",
        "    \"/content/transcript_1.txt\",\n",
        "    docs_cleaned[\"/content/transcript_1.txt\"],\n",
        "    segmented_transcripts[\"/content/transcript_1.txt\"]\n",
        ")\n",
        "\n",
        "print(f\"üìÑ transcript_1.txt ‚Üí {len(chunks_transcript1_adaptive)} chunks (adaptive)\")\n",
        "print(\"\\nSample transcript chunk:\\n\", chunks_transcript1_adaptive[0][\"text\"][:500], \"...\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5LQM8ahHWzHb",
        "outputId": "1b0be1ba-a165-43b6-8acf-f7e770d52dd1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÑ transcript_1.txt ‚Üí 5 chunks (adaptive)\n",
            "\n",
            "Sample transcript chunk:\n",
            " we're going to quickly talk about functions of a complex variable and suppose z is a complex number or z say it's a it's a complex variable we say that f of z is a function of z if f of z takes a unique value for a given z in other words for one value of z you cannot have two different values of f of z if that's the case you have only one value of f of z for a given z then we say that f of z is a function of a complex variable so there are many files i'll give you a few examples of functions tha ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Checking Chunking Performance:\n",
        "\n",
        "Adding a chunk stats summary function to measure:\n",
        "\n",
        "- Number of chunks per doc\n",
        "\n",
        "- Avg/min/max words per chunk\n",
        "\n",
        "- Run it across all 6 docs (notes.pdf + 5 transcripts).\n",
        "\n",
        "- Adjust chunk sizes if any file looks too coarse or too fine."
      ],
      "metadata": {
        "id": "9zodpBZ3XQkm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def chunk_stats(chunks):\n",
        "    \"\"\"Compute statistics (num chunks, avg/min/max words) for a list of chunks.\"\"\"\n",
        "    lengths = [len(c[\"text\"].split()) for c in chunks]\n",
        "    return {\n",
        "        \"num_chunks\": len(chunks),\n",
        "        \"avg_words\": round(sum(lengths)/len(lengths), 2) if lengths else 0,\n",
        "        \"min_words\": min(lengths) if lengths else 0,\n",
        "        \"max_words\": max(lengths) if lengths else 0\n",
        "    }"
      ],
      "metadata": {
        "id": "sIHDSIRnXS1j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply adaptive chunking to all docs\n",
        "all_chunks = {}\n",
        "for name, text in docs_cleaned.items():\n",
        "    if name.endswith(\".pdf\"):\n",
        "        chunks = chunk_document_adaptive(name, text)\n",
        "    else:\n",
        "        chunks = chunk_document_adaptive(name, text, segmented_transcripts[name])\n",
        "    all_chunks[name] = chunks"
      ],
      "metadata": {
        "id": "mp5aVONDXbEe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build summary DataFrame\n",
        "stats_summary = {name: chunk_stats(chunks) for name, chunks in all_chunks.items()}\n",
        "import pandas as pd\n",
        "df_stats = pd.DataFrame(stats_summary).T\n",
        "df_stats"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "5ALicSV0XcSb",
        "outputId": "e56967eb-1ba6-4669-dbab-a6bf240782d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                           num_chunks  avg_words  min_words  max_words\n",
              "/content/notes.pdf              156.0     399.77      364.0      400.0\n",
              "/content/transcript_1.txt         5.0     174.60      153.0      180.0\n",
              "/content/transcript_2.txt        14.0     177.00      138.0      180.0\n",
              "/content/transcript_3.txt         8.0     165.12       61.0      180.0\n",
              "/content/transcript_4.txt         7.0     164.71       73.0      180.0\n",
              "/content/transcript_5.txt        41.0     177.44       75.0      180.0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4efb51a3-b363-4f48-97cc-2e615a59272b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>num_chunks</th>\n",
              "      <th>avg_words</th>\n",
              "      <th>min_words</th>\n",
              "      <th>max_words</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>/content/notes.pdf</th>\n",
              "      <td>156.0</td>\n",
              "      <td>399.77</td>\n",
              "      <td>364.0</td>\n",
              "      <td>400.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>/content/transcript_1.txt</th>\n",
              "      <td>5.0</td>\n",
              "      <td>174.60</td>\n",
              "      <td>153.0</td>\n",
              "      <td>180.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>/content/transcript_2.txt</th>\n",
              "      <td>14.0</td>\n",
              "      <td>177.00</td>\n",
              "      <td>138.0</td>\n",
              "      <td>180.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>/content/transcript_3.txt</th>\n",
              "      <td>8.0</td>\n",
              "      <td>165.12</td>\n",
              "      <td>61.0</td>\n",
              "      <td>180.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>/content/transcript_4.txt</th>\n",
              "      <td>7.0</td>\n",
              "      <td>164.71</td>\n",
              "      <td>73.0</td>\n",
              "      <td>180.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>/content/transcript_5.txt</th>\n",
              "      <td>41.0</td>\n",
              "      <td>177.44</td>\n",
              "      <td>75.0</td>\n",
              "      <td>180.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4efb51a3-b363-4f48-97cc-2e615a59272b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4efb51a3-b363-4f48-97cc-2e615a59272b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4efb51a3-b363-4f48-97cc-2e615a59272b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-d975f8ea-91a9-455e-9bf8-9b8733a50dda\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d975f8ea-91a9-455e-9bf8-9b8733a50dda')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-d975f8ea-91a9-455e-9bf8-9b8733a50dda button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_937bd6dd-33c0-4c1a-bd13-31d9953e344e\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_stats')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_937bd6dd-33c0-4c1a-bd13-31d9953e344e button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_stats');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_stats",
              "summary": "{\n  \"name\": \"df_stats\",\n  \"rows\": 6,\n  \"fields\": [\n    {\n      \"column\": \"num_chunks\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 59.088916050305066,\n        \"min\": 5.0,\n        \"max\": 156.0,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          156.0,\n          5.0,\n          41.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"avg_words\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 93.25240665348356,\n        \"min\": 164.71,\n        \"max\": 399.77,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          399.77,\n          174.6,\n          177.44\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"min_words\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 114.1998248685172,\n        \"min\": 61.0,\n        \"max\": 364.0,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          364.0,\n          153.0,\n          75.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"max_words\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 89.81462390204987,\n        \"min\": 180.0,\n        \"max\": 400.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          180.0,\n          400.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Chunking Summary\n",
        "\n",
        "**notes.pdf**\n",
        "\n",
        "* 156 chunks\n",
        "* Avg size \\~400 words (tight range 364‚Äì400) ‚Üí exactly as intended.\n",
        "* Good for structured, long text.\n",
        "\n",
        "**transcripts**\n",
        "\n",
        "* Transcript\\_1 ‚Üí 5 chunks, avg 175 words.\n",
        "* Transcript\\_2 ‚Üí 14 chunks, avg 177 words.\n",
        "* Transcript\\_3 ‚Üí 8 chunks, avg 165 words.\n",
        "* Transcript\\_4 ‚Üí 7 chunks, avg 165 words.\n",
        "* Transcript\\_5 ‚Üí 41 chunks, avg 177 words.\n",
        "\n",
        "\n",
        "All transcripts are chunked into \\~160‚Äì180 word units. That‚Äôs **coherent and consistent**.\n",
        "\n",
        "* `min_words` occasionally dips (61, 73, 75) ‚Üí happens at end-of-file leftovers, not a big issue.\n",
        "* Overall, transcript chunking is **much better** than before.\n",
        "\n",
        "---\n",
        "\n",
        "### Assessment\n",
        "\n",
        "* Chunk sizes are balanced:\n",
        "\n",
        "  * **notes.pdf**: \\~400 words (dense, textbook style).\n",
        "  * **transcripts**: \\~160‚Äì180 words (spoken lecture).\n",
        "* This setup ensures each chunk is manageable for the LLM (both for question generation and context)."
      ],
      "metadata": {
        "id": "IwGlayhCXduj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Step 3: Question Generation**.\n",
        "The goal is: given a **chunk of text**, generate a few **MCQs** (question + correct answer + distractors) in a JSON-like format.\n",
        "\n",
        "1. **Baseline Function**\n",
        "\n",
        "   * Use a prompt template with:\n",
        "\n",
        "     * Context (chunk text)\n",
        "     * Instructions to generate MCQs in JSON schema\n",
        "   * Ask for **2‚Äì3 questions per chunk** (to keep cost manageable).\n",
        "\n",
        "2. **JSON Schema**\n",
        "   Keep it simple for now:\n",
        "\n",
        "   ```json\n",
        "   {\n",
        "     \"question\": \"...\",\n",
        "     \"choices\": [\"A\", \"B\", \"C\", \"D\"],\n",
        "     \"correct_answer\": \"B\"\n",
        "   }\n",
        "   ```\n",
        "\n",
        "3. **LLM API Hook**\n",
        "\n",
        "   * In Colab, you‚Äôll need to connect to OpenAI/Anthropic/etc.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "r4Lk9-NzXrZ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Paste your key here\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"Your Key Here\""
      ],
      "metadata": {
        "id": "ZvwgnuqTZX_-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from openai import OpenAI\n",
        "import json\n",
        "\n",
        "# Initialize OpenAI client\n",
        "client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"))"
      ],
      "metadata": {
        "id": "9BxaREtdYCqy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prompt template\n",
        "def build_prompt(chunk_text, n_questions=3):\n",
        "    return f\"\"\"\n",
        "You are a helpful assistant that generates multiple-choice questions (MCQs).\n",
        "Use the following text to create {n_questions} conceptual MCQs.\n",
        "\n",
        "TEXT:\n",
        "\\\"\\\"\\\"{chunk_text}\\\"\\\"\\\"\n",
        "\n",
        "Rules:\n",
        "- Each MCQ should test conceptual understanding (not just word recall).\n",
        "- Provide exactly 4 options per question.\n",
        "- Exactly 1 correct answer.\n",
        "- Distractors must be plausible but incorrect.\n",
        "- In the JSON, the \"correct_answer\" must be the FULL TEXT of the correct option,\n",
        "  exactly as it appears in the \"choices\" list.\n",
        "\n",
        "Return the output as a valid JSON list, like this:\n",
        "[\n",
        "  {{\n",
        "    \"question\": \"What is 2+2?\",\n",
        "    \"choices\": [\"1\", \"2\", \"3\", \"4\"],\n",
        "    \"correct_answer\": \"4\"\n",
        "  }}\n",
        "]\n",
        "    \"\"\"\n",
        "\n",
        "def generate_mcqs_for_chunk(chunk_text, n_questions=3, model=\"gpt-4o-mini\"):\n",
        "    prompt = build_prompt(chunk_text, n_questions=n_questions)\n",
        "    response = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        temperature=0.7,\n",
        "    )\n",
        "    raw_output = response.choices[0].message.content.strip()\n",
        "\n",
        "    try:\n",
        "        mcqs = json.loads(raw_output)\n",
        "    except:\n",
        "        print(\"Could not parse JSON, returning raw output\")\n",
        "        mcqs = raw_output\n",
        "    return mcqs"
      ],
      "metadata": {
        "id": "vS7qH_UUZl08"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def safe_json_parse(output_str):\n",
        "    # Remove Markdown code fences if present\n",
        "    cleaned = output_str.strip()\n",
        "    if cleaned.startswith(\"```\"):\n",
        "        cleaned = re.sub(r\"```(?:json)?\", \"\", cleaned)\n",
        "        cleaned = cleaned.strip(\"` \\n\")\n",
        "    try:\n",
        "        return json.loads(cleaned)\n",
        "    except Exception as e:\n",
        "        print(\"Still could not parse JSON:\", e)\n",
        "        return cleaned\n",
        "\n",
        "def generate_mcqs_for_chunk(chunk_text, n_questions=3, model=\"gpt-4o-mini\"):\n",
        "    prompt = build_prompt(chunk_text, n_questions=n_questions)\n",
        "    response = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        temperature=0.7,\n",
        "    )\n",
        "    raw_output = response.choices[0].message.content.strip()\n",
        "    mcqs = safe_json_parse(raw_output)\n",
        "    return mcqs"
      ],
      "metadata": {
        "id": "Ic08VlZoZoJf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test again\n",
        "sample_chunk = all_chunks[\"/content/transcript_1.txt\"][0][\"text\"]\n",
        "mcqs = generate_mcqs_for_chunk(sample_chunk, n_questions=2)\n",
        "print(json.dumps(mcqs, indent=2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UI0KtSXFaqq_",
        "outputId": "92ab2c34-7abd-4ae2-c5fd-671cf8cb1b0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\n",
            "  {\n",
            "    \"question\": \"What characterizes a function of a complex variable f(z)?\",\n",
            "    \"choices\": [\n",
            "      \"It can take multiple values for a single input z.\",\n",
            "      \"It must produce a unique value for each value of z.\",\n",
            "      \"It is always linear in nature.\",\n",
            "      \"It can only operate on real numbers.\"\n",
            "    ],\n",
            "    \"correct_answer\": \"It must produce a unique value for each value of z.\"\n",
            "  },\n",
            "  {\n",
            "    \"question\": \"Given the complex number z = 2 + 3i, what is the magnitude of z?\",\n",
            "    \"choices\": [\n",
            "      \"5\",\n",
            "      \"13\",\n",
            "      \"\\u221a13\",\n",
            "      \"2 + 3i\"\n",
            "    ],\n",
            "    \"correct_answer\": \"\\u221a13\"\n",
            "  }\n",
            "]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What this does\n",
        "\n",
        "* Builds a structured prompt.\n",
        "* Sends it to the LLM.\n",
        "* Returns parsed JSON if possible.\n",
        "* Generates **2 sample questions** from transcript\\_1‚Äôs first chunk.\n",
        "\n",
        "### Step 4: Quality Control ‚Äì Schema Validation.\n",
        "\n",
        "The idea is: after generating MCQs, we‚Äôll validate each entry against our schema rules.\n"
      ],
      "metadata": {
        "id": "wsodno9MYP3E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def validate_mcq(mcq):\n",
        "    errors = []\n",
        "\n",
        "    # Required keys\n",
        "    for key in [\"question\", \"choices\", \"correct_answer\"]:\n",
        "        if key not in mcq:\n",
        "            errors.append(f\"Missing key: {key}\")\n",
        "            return errors  # skip further checks\n",
        "\n",
        "    # Question text\n",
        "    if not isinstance(mcq[\"question\"], str) or len(mcq[\"question\"].strip()) < 5:\n",
        "        errors.append(\"Invalid question text\")\n",
        "\n",
        "    # Choices\n",
        "    if not isinstance(mcq[\"choices\"], list):\n",
        "        errors.append(\"Choices must be a list\")\n",
        "    elif len(mcq[\"choices\"]) != 4:\n",
        "        errors.append(f\"Expected 4 choices, got {len(mcq['choices'])}\")\n",
        "\n",
        "    # Correct answer must be in choices\n",
        "    if mcq[\"correct_answer\"] not in mcq[\"choices\"]:\n",
        "        errors.append(\"Correct answer not in choices\")\n",
        "\n",
        "    return errors\n",
        "\n",
        "\n",
        "def validate_mcqs(mcqs):\n",
        "    if not isinstance(mcqs, list):\n",
        "        return [\"MCQs are not a list\"], []\n",
        "\n",
        "    all_errors = {}\n",
        "    valid_mcqs = []\n",
        "    for i, mcq in enumerate(mcqs):\n",
        "        errs = validate_mcq(mcq)\n",
        "        if errs:\n",
        "            all_errors[f\"Q{i+1}\"] = errs\n",
        "        else:\n",
        "            valid_mcqs.append(mcq)\n",
        "    return all_errors, valid_mcqs"
      ],
      "metadata": {
        "id": "6CC3VcIAYUDw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test on sample chunk\n",
        "sample_chunk = all_chunks[\"/content/transcript_4.txt\"][0][\"text\"]\n",
        "mcqs = generate_mcqs_for_chunk(sample_chunk, n_questions=2)"
      ],
      "metadata": {
        "id": "ng7ZvnimbLKx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "errors, valid = validate_mcqs(mcqs)\n",
        "print(\" Errors:\", errors)\n",
        "print(\"Valid MCQs:\", json.dumps(valid, indent=2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zFAsvfblbOKC",
        "outputId": "7b6b9a62-0816-4291-ab0d-ea60cfa9ee89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚ùå Errors: {}\n",
            "‚úÖ Valid MCQs: [\n",
            "  {\n",
            "    \"question\": \"Why do roots of polynomials with real coefficients occur in conjugate pairs?\",\n",
            "    \"choices\": [\n",
            "      \"Because complex roots must have the same real part.\",\n",
            "      \"Because the coefficients of the polynomial are complex.\",\n",
            "      \"Because every polynomial with real coefficients has only real roots.\",\n",
            "      \"Because complex roots come in pairs in conjugate forms.\"\n",
            "    ],\n",
            "    \"correct_answer\": \"Because complex roots come in pairs in conjugate forms.\"\n",
            "  },\n",
            "  {\n",
            "    \"question\": \"What are the roots of the quadratic equation x\\u00b2 - 2x + 5 = 0?\",\n",
            "    \"choices\": [\n",
            "      \"1 + 2j and 1 - 2j\",\n",
            "      \"2 + \\u221a(4-20) and 2 - \\u221a(4-20)\",\n",
            "      \"2 + 2j and 2 - 2j\",\n",
            "      \"1 + j2 and 1 - j2\"\n",
            "    ],\n",
            "    \"correct_answer\": \"1 + j2 and 1 - j2\"\n",
            "  }\n",
            "]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Full Question Generation Pipeline"
      ],
      "metadata": {
        "id": "wBRcy7fwbP0I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import datetime\n",
        "\n",
        "# Generate, validate, and repair pipeline\n",
        "\n",
        "def generate_and_validate_chunk(chunk_text, n_questions=2, model=\"gpt-4o-mini\"):\n",
        "    \"\"\"Generate MCQs for a chunk and validate them.\"\"\"\n",
        "    mcqs = generate_mcqs_for_chunk(chunk_text, n_questions=n_questions, model=model)\n",
        "    errors, valid = validate_mcqs(mcqs)\n",
        "    return valid, errors\n",
        "\n",
        "\n",
        "def run_pipeline(all_chunks, n_questions=2, model=\"gpt-4o-mini\"):\n",
        "    \"\"\"Run the full pipeline across all chunks from all documents.\"\"\"\n",
        "    all_mcqs = []\n",
        "    error_log = {}\n",
        "\n",
        "    for doc, chunks in all_chunks.items():\n",
        "        for idx, ch in enumerate(chunks):\n",
        "            valid, errors = generate_and_validate_chunk(ch[\"text\"], n_questions, model)\n",
        "\n",
        "            # Attach metadata\n",
        "            for q in valid:\n",
        "                q.update({\n",
        "                    \"doc\": doc,\n",
        "                    \"section\": ch[\"section\"],\n",
        "                    \"chunk_index\": idx\n",
        "                })\n",
        "                all_mcqs.append(q)\n",
        "\n",
        "            if errors:\n",
        "                error_log[f\"{doc}_chunk{idx}\"] = errors\n",
        "\n",
        "    return all_mcqs, error_log\n",
        "\n",
        "\n",
        "def export_mcqs_json(mcqs, out_path=\"questions.json\"):\n",
        "    \"\"\"Export final MCQs to JSON file with metadata header.\"\"\"\n",
        "    output = {\n",
        "        \"assignment\": \"Scalable Question Generation System\",\n",
        "        \"generated_at\": datetime.datetime.utcnow().isoformat() + \"Z\",\n",
        "        \"num_questions\": len(mcqs),\n",
        "        \"questions\": mcqs\n",
        "    }\n",
        "    with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(output, f, indent=2, ensure_ascii=False)\n",
        "    print(f\"‚úÖ Exported {len(mcqs)} questions to {out_path}\")\n",
        "    return out_path"
      ],
      "metadata": {
        "id": "GKogX8RdcIQV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run on all docs\n",
        "# To keep cost low in testing, set n_questions=1\n",
        "all_mcqs, errors = run_pipeline(all_chunks, n_questions=1)\n",
        "\n",
        "print(f\"Generated {len(all_mcqs)} valid questions\")\n",
        "print(f\"Errors: {len(errors)} problem chunks\")\n",
        "\n",
        "# Export JSON deliverable\n",
        "export_mcqs_json(all_mcqs, out_path=\"/content/questions.json\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        },
        "id": "ETY3bdgzcK6_",
        "outputId": "e5d417b0-904e-43d8-ad80-a0e114561fe3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated 231 valid questions\n",
            "Errors: 0 problem chunks\n",
            "‚úÖ Exported 231 questions to /content/questions.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2218850253.py:41: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  \"generated_at\": datetime.datetime.utcnow().isoformat() + \"Z\",\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/questions.json'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Increasing Question Answer Quality\n",
        "\n",
        "1. **Deduplication (semantic)**\n",
        "\n",
        "- Use embeddings (e.g. OpenAI text-embedding-3-small) or sentence transformers to catch near-duplicate question stems.\n",
        "\n",
        "- Drop duplicates with cosine similarity > 0.9.\n",
        "\n",
        "2. **Notation Cleanup**\n",
        "\n",
        "- Regex replacements:\n",
        "\n",
        "- Replace œñ ‚Üí Œ∏\n",
        "\n",
        "- Replace ‚Üí ‚Üí \"->\"\n",
        "\n",
        "3. **Normalize subscripts (n0 ‚Üí n‚ÇÄ)**\n",
        "\n",
        "- Strip stray formatting artifacts (\\n, ‚Ä¶, ‚ñ°).\n",
        "\n",
        "- Difficulty Tagging (Bloom‚Äôs Taxonomy inspired)\n",
        "\n",
        "4. **Simple heuristic:**\n",
        "\n",
        "- Easy: ‚ÄúWhat is‚Ä¶?‚Äù, ‚ÄúDefine‚Ä¶‚Äù, ‚ÄúWhich of the following‚Ä¶‚Äù (recall/understand).\n",
        "\n",
        "- Medium: ‚ÄúWhy‚Ä¶?‚Äù, ‚ÄúWhat happens when‚Ä¶?‚Äù, ‚ÄúWhich property holds if‚Ä¶?‚Äù (apply/analyze).\n",
        "\n",
        "- Hard: ‚ÄúEvaluate‚Ä¶‚Äù, ‚ÄúCompare‚Ä¶‚Äù, ‚ÄúWhich best explains‚Ä¶‚Äù, scenario-based (evaluate/create).\n",
        "\n",
        "- Add \"difficulty\": \"easy|medium|hard\" to each MCQ.\n",
        "\n",
        "5. **Export Enhanced JSON**\n",
        "\n",
        "- Include metadata:\n",
        "\n",
        "- Number of questions before/after dedup.\n",
        "\n",
        "- Distribution of difficulties."
      ],
      "metadata": {
        "id": "nbuLlhnwcMSF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import json\n",
        "from openai import OpenAI\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ],
      "metadata": {
        "id": "AH5yv0baarwH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"))"
      ],
      "metadata": {
        "id": "TrNcbGVvbDsG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Notation cleanup\n",
        "def clean_notation(text):\n",
        "    text = text.replace(\"œñ\", \"Œ∏\")\n",
        "    text = text.replace(\"‚Üí\", \"->\")\n",
        "    text = re.sub(r\"\\bn0\\b\", \"n‚ÇÄ\", text)\n",
        "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
        "    return text\n",
        "\n",
        "def clean_mcq(mcq):\n",
        "    mcq[\"question\"] = clean_notation(mcq[\"question\"])\n",
        "    mcq[\"choices\"] = [clean_notation(c) for c in mcq[\"choices\"]]\n",
        "    mcq[\"correct_answer\"] = clean_notation(mcq[\"correct_answer\"])\n",
        "    return mcq"
      ],
      "metadata": {
        "id": "kS5PncZtbIUG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  2. Deduplication\n",
        "def embed_texts(texts, model=\"text-embedding-3-small\"):\n",
        "    embs = [client.embeddings.create(model=model, input=t).data[0].embedding for t in texts]\n",
        "    return np.array(embs)\n",
        "\n",
        "def deduplicate_mcqs(mcqs, threshold=0.9):\n",
        "    stems = [m[\"question\"] for m in mcqs]\n",
        "    embs = embed_texts(stems)\n",
        "    keep = []\n",
        "    seen = set()\n",
        "    for i, emb in enumerate(embs):\n",
        "        if i in seen: continue\n",
        "        keep.append(mcqs[i])\n",
        "        sims = cosine_similarity([emb], embs)[0]\n",
        "        for j, s in enumerate(sims):\n",
        "            if j != i and s >= threshold:\n",
        "                seen.add(j)\n",
        "    return keep"
      ],
      "metadata": {
        "id": "qW5uCKrablca"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  3. Difficulty tagging\n",
        "def tag_difficulty(q):\n",
        "    qtext = q[\"question\"].lower()\n",
        "    if qtext.startswith((\"what is\", \"which of the following\", \"define\")):\n",
        "        return \"easy\"\n",
        "    elif qtext.startswith((\"why\", \"what happens\", \"which property\")):\n",
        "        return \"medium\"\n",
        "    else:\n",
        "        return \"hard\"\n",
        "\n",
        "def enrich_mcqs(mcqs):\n",
        "    enhanced = []\n",
        "    for mcq in mcqs:\n",
        "        mcq = clean_mcq(mcq)\n",
        "        mcq[\"difficulty\"] = tag_difficulty(mcq)\n",
        "        enhanced.append(mcq)\n",
        "    return enhanced"
      ],
      "metadata": {
        "id": "4COc20Fcboak"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  4. End-to-end enhancement\n",
        "def enhance_questions(path_in, path_out=\"questions_enhanced.json\"):\n",
        "    with open(path_in, \"r\", encoding=\"utf-8\") as f:\n",
        "        data = json.load(f)\n",
        "    mcqs = data[\"questions\"]\n",
        "\n",
        "    # Clean + tag\n",
        "    mcqs = enrich_mcqs(mcqs)\n",
        "\n",
        "    # Deduplicate\n",
        "    before = len(mcqs)\n",
        "    mcqs = deduplicate_mcqs(mcqs)\n",
        "    after = len(mcqs)\n",
        "\n",
        "    # Export\n",
        "    out = {\n",
        "        \"assignment\": data[\"assignment\"],\n",
        "        \"generated_at\": data[\"generated_at\"],\n",
        "        \"before_dedup\": before,\n",
        "        \"after_dedup\": after,\n",
        "        \"questions\": mcqs\n",
        "    }\n",
        "    with open(path_out, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(out, f, indent=2, ensure_ascii=False)\n",
        "    print(f\"‚úÖ Enhanced questions saved to {path_out} (dedup {before}->{after})\")\n",
        "    return out"
      ],
      "metadata": {
        "id": "oC5Xeu2bbqKJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "enhanced = enhance_questions(\"/content/questions.json\", path_out=\"/content/questions_enhanced.json\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yiktc4Oibsku",
        "outputId": "6739eae0-8bc5-4ed9-a43c-ec655fb92150"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Enhanced questions saved to /content/questions_enhanced.json (dedup 231->224)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Before dedup: {enhanced['before_dedup']}, After dedup: {enhanced['after_dedup']}\")\n",
        "print(\"Sample question:\", enhanced[\"questions\"][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XgrpI_KwcMz5",
        "outputId": "2c133190-95ff-4738-aa6b-1cfbde7a1375"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before dedup: 231, After dedup: 224\n",
            "Sample question: {'question': 'Which of the following concepts is essential for understanding the geometric interpretation of complex numbers?', 'choices': ['Magnitude and Phase Representation', 'Trigonometric Identities', 'Geometric Series', 'Functions of a Real Variable'], 'correct_answer': 'Magnitude and Phase Representation', 'doc': '/content/notes.pdf', 'section': 'Contents Mathematical Preliminaries 1.1 Trigonomet', 'chunk_index': 0, 'difficulty': 'easy'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The **enhanced `questions_enhanced.json` file**, relative to both the **assignment requirements** and the **bonus enhancements** we planned:\n",
        "\n",
        "---\n",
        "\n",
        "## Assignment Requirements\n",
        "\n",
        "1. **Question generation from provided materials**\n",
        "\n",
        "   * ‚úî Questions are clearly based on content from *notes.pdf* and the transcripts (complex numbers, Euler‚Äôs formula, signals, LTI systems, etc.) .\n",
        "\n",
        "2. **Multiple-choice format**\n",
        "\n",
        "   * ‚úî Every question has **4 choices** with exactly one correct answer.\n",
        "\n",
        "3. **Automated & scalable pipeline**\n",
        "\n",
        "   * ‚úî The workflow built is fully automated: chunking ‚Üí generation ‚Üí validation ‚Üí aggregation ‚Üí export.\n",
        "   * ‚úî Scales across hundreds of chunks (final output = **224 valid questions after deduplication**).\n",
        "\n",
        "---\n",
        "\n",
        "## Bonus Enhancements\n",
        "\n",
        "1. **Quality control**\n",
        "\n",
        "   * ‚úî Schema validation ensured correct structure.\n",
        "   * ‚úî Deduplication removed near-duplicate questions (from 231 ‚Üí 224).\n",
        "\n",
        "2. **Difficulty tagging**\n",
        "\n",
        "   * ‚úî Each question has a `\"difficulty\": \"easy\" | \"medium\" | \"hard\"` tag.\n",
        "   * Distribution looks balanced across levels (quick scan shows many ‚Äúeasy‚Äù, some ‚Äúmedium‚Äù, and a healthy set of ‚Äúhard‚Äù).\n",
        "\n",
        "3. **Notation cleanup**\n",
        "\n",
        "   * Partially complete. Symbols like `œñ`, `œë`, `->`, and `Œµ[n -> n‚ÇÄ]` still remain in some questions. These were carried from the parsed text.\n",
        "   * The cleanup regex helped, but a second pass (mapping `œñ/œë ‚Üí Œ∏`, `-> ‚Üí ‚Üí`, and LaTeX-style math) would polish the output further.\n",
        "\n",
        "---\n",
        "\n",
        "##  Key Stats\n",
        "\n",
        "* **Before deduplication**: 231\n",
        "* **After deduplication**: 224&#x20;\n",
        "* **Coverage**: Both lecture notes and transcripts.\n",
        "* **Difficulty spread**: Easy/medium/hard present.\n",
        "\n",
        "---\n",
        "\n",
        "##  Notable Points\n",
        "\n",
        "* Some mathematical formatting could confuse learners if left as-is (e.g., `\"sin(Œ∏ ¬± œ±)\"`, `\"Œµ[n -> n‚ÇÄ]\"`).\n",
        "* Conceptual quality is strong: questions test understanding, not just recall.\n",
        "* Metadata (`doc`, `section`, `chunk_index`) is preserved, which is useful if you need traceability.\n",
        "\n",
        "---\n",
        "\n",
        "##  Conclusion\n",
        "\n",
        "* All **core assignment requirements** are satisfied.\n",
        "* Both **bonus enhancements** (quality control + difficulty tagging) are implemented.\n",
        "* Only **notation cleanup** could be refined further to improve readability."
      ],
      "metadata": {
        "id": "99AfFoOecP7Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Limitations & Future Improvements\n",
        "\n",
        "## 1) Inputs & Parsing\n",
        "\n",
        "**What‚Äôs good:** Robust PDF/TXT ingestion; custom transcript segmentation fixed the ‚Äúone giant sentence‚Äù issue.\n",
        "\n",
        "**Limitations**\n",
        "\n",
        "* **PDF artifacts:** TOC dotted leaders, headers/footers, math glyphs (e.g., œñ, œë) survive extraction and leak into questions.\n",
        "* **Math layout loss:** Fractions, subscripts/superscripts, inline LaTeX get flattened, which can mislead distractors.\n",
        "\n",
        "**Improvements**\n",
        "\n",
        "* Prefer `pymupdf` text blocks + font cues to better detect headings and strip boilerplate.\n",
        "* Add `ftfy` + a richer normalization map (e.g., unicode minus vs hyphen, arrows, subscripts).\n",
        "* Optional: parse LaTeX/math with a mini normalizer (regex ‚Üí canonical forms; e.g., `e^{jŒ∏}`, `x[n‚àín‚ÇÄ]`).\n",
        "\n",
        "**Acceptance checks**\n",
        "\n",
        "* ‚â•95% reduction of dotted leader lines in TOC.\n",
        "* No stray page numbers/headers in the first 3 pages.\n",
        "* Symbol sanity unit tests (œñ‚ÜíŒ∏, ‚Äú->‚Äù‚Üí‚Äú‚Üí‚Äù, hyphen/minus normalization).\n",
        "\n",
        "---\n",
        "\n",
        "## 2) Cleaning, Segmentation & Chunking\n",
        "\n",
        "**What‚Äôs good:** Sentence ranges now \\~12‚Äì25 words; adaptive chunk size (notes \\~400w, transcripts \\~160‚Äì180w) is consistent and LLM-friendly.\n",
        "\n",
        "**Limitations**\n",
        "\n",
        "* **Hard word windows:** Fixed chunk sizes can still cut across conceptual boundaries.\n",
        "* **Coverage drift:** Some chunks dominate with low-value lines (e.g., listy TOC or repetitive spoken fillers).\n",
        "\n",
        "**Improvements**\n",
        "\n",
        "* **Semantic chunking:** Split on embedding similarity drops; merge short segments until a token budget (e.g., \\~1.2‚Äì1.8k tokens) is met.\n",
        "* **Adaptive stride:** Increase overlap for concept-dense sections; reduce for repetitive regions.\n",
        "* **Coverage control:** After chunking a document, cluster stems and enforce per-cluster sampling to ensure topic coverage.\n",
        "\n",
        "**Acceptance checks**\n",
        "\n",
        "* Topic coverage metric: cosine similarity clustering across stems ‚Üí ‚â•90% of clusters represented.\n",
        "* Mean chunk token count within target ¬±15%.\n",
        "\n",
        "---\n",
        "\n",
        "## 3) Question Generation (LLM)\n",
        "\n",
        "**What‚Äôs good:** Stable JSON, correct\\_answer matches choices, conceptual (not purely copy-paste), runs at scale.\n",
        "\n",
        "**Limitations**\n",
        "\n",
        "* **Grounding not enforced:** We don‚Äôt require an explicit supporting snippet; occasional mild drift/hallucination can slip through.\n",
        "* **Distractor calibration:** Plausible, but not systematically ‚Äúsame type / common misconception / near-miss‚Äù enforced.\n",
        "* **Model justification:** We used `gpt-4o-mini` (good speed/\\$) without a comparison run.\n",
        "\n",
        "**Improvements**\n",
        "\n",
        "* **Add evidence span:** Update prompt to return a short `evidence_span` (‚â§ 25 words) copied from the chunk; reject if absent.\n",
        "* **Distractor rubric:** In prompt, require each distractor to be: (1) same semantic type as the correct answer, (2) explain a typical misconception, (3) not true under the given assumptions.\n",
        "* **Model bake-off:** Run a 20-chunk A/B on `gpt-4o`, `gpt-4o-mini`, and (optionally) Claude/Gemini; keep the best cost-quality mix.\n",
        "\n",
        "**Acceptance checks**\n",
        "\n",
        "* ‚â•95% of items include a valid, verbatim `evidence_span` present in the source chunk.\n",
        "* Human spot-check: ‚â•80% of distractors rated ‚Äúplausible‚Äù by a rater rubric.\n",
        "\n",
        "---\n",
        "\n",
        "## 4) Quality Control (beyond schema)\n",
        "\n",
        "**What‚Äôs good:** Schema validation + JSON repair + dedup via embeddings; difficulty tags present.\n",
        "\n",
        "**Limitations**\n",
        "\n",
        "* **Answerability not measured:** We don‚Äôt re-answer each MCQ from the same chunk.\n",
        "* **No contradiction test:** We don‚Äôt check if distractors are explicitly contradicted by the chunk.\n",
        "* **Dedup risk:** Single-threshold dedup can false-merge distinct stems (false positives) or miss paraphrases (false negatives).\n",
        "* **Difficulty tagging is heuristic:** Based on question openers; not Bloom-aware or context-aware.\n",
        "\n",
        "**Improvements**\n",
        "\n",
        "* **Answerability check:** Ask the LLM (or a smaller verifier) to answer the MCQ using only the chunk; it must pick the same `correct_answer`. Reject/repair otherwise.\n",
        "* **Entailment/contradiction:** Use an NLI model (or LLM) to assert: (chunk ‚áí correct) and (chunk ‚üÇ distractors). Flag unsupported or contradicted items.\n",
        "* **Two-stage dedup:** (1) Fast cosine prefilter, (2) pairwise LLM ‚Äúare these duplicates?‚Äù check on close pairs only.\n",
        "* **LLM difficulty tagger:** Prompt a classifier (‚ÄúLabel as Remember/Understand/Apply/Analyze/Evaluate/Create and map to easy/medium/hard‚Äù) and compare with heuristics; keep consensus or the higher of the two.\n",
        "\n",
        "**Acceptance checks**\n",
        "\n",
        "* **Answerability pass rate** ‚â• 90%.\n",
        "* **Unsupported flag rate** ‚â§ 5%.\n",
        "* **Duplicate rate after two-stage** ‚â§ 2%.\n",
        "* Difficulty distribution target (e.g., 55/35/10% easy/medium/hard) met within ¬±5%.\n",
        "\n",
        "---\n",
        "\n",
        "## 5) Notation & Math Cleanup\n",
        "\n",
        "**What‚Äôs good:** Initial unicode mapping and whitespace normalization; many questions already readable.\n",
        "\n",
        "**Limitations**\n",
        "\n",
        "* Stray glyphs remain (œñ, œë, mixed arrows, subscript rendering), which can degrade clarity.\n",
        "\n",
        "**Improvements**\n",
        "\n",
        "* Expand symbol map (minus, dot, times, subscripts ‚ÇÄ‚Ä¶‚Çâ, arrows, ¬±, ‚â§/‚â•).\n",
        "* Normalize common math phrases (e.g., ‚Äúe to the j theta‚Äù ‚Üí ‚Äúe^{jŒ∏}‚Äù OR consistently plain-text if you avoid LaTeX).\n",
        "* Optional: LaTeX mode toggle‚Äîemit either plain text or simple LaTeX for math segments.\n",
        "\n",
        "**Acceptance checks**\n",
        "\n",
        "* 0 unresolved glyphs from a predefined ‚Äúforbidden symbol‚Äù list.\n",
        "* Manual math readability spot-check: ‚â•90% ‚Äúclear‚Äù ratings.\n",
        "\n",
        "---\n",
        "\n",
        "## 6) Scalability, Cost & Reliability\n",
        "\n",
        "**What‚Äôs good:** Works across \\~230 chunks reliably.\n",
        "\n",
        "**Limitations**\n",
        "\n",
        "* **Sequential calls:** Latency increases linearly with chunks.\n",
        "* **No formal token/cost budgeting:** We don‚Äôt cap spend per run.\n",
        "* **Limited resilience:** No exponential backoff, jitter, or intelligent retries; rate limits can interrupt.\n",
        "\n",
        "**Improvements**\n",
        "\n",
        "* **Concurrency:** Async batches with rate-limit aware semaphores; backoff with jitter on 429s/5xx.\n",
        "* **Caching:** Hash(prompt+model) ‚Üí sqlite/joblib cache to avoid recomputing.\n",
        "* **Budgets:** Token estimator + hard stop (e.g., ‚Äúmax \\$X or Y tokens‚Äù).\n",
        "* **Observability:** Structured logs (per chunk latency/tokens), progress bar, and per-model cost summary.\n",
        "\n",
        "**Acceptance checks**\n",
        "\n",
        "* End-to-end wall-time & \\$ reported at run end.\n",
        "* Cache hit-rate metric (target ‚â• 30% on iterative runs).\n",
        "\n",
        "---\n",
        "\n",
        "## 7) Data & Output Governance\n",
        "\n",
        "**What‚Äôs good:** Single JSON with metadata (doc, section, chunk\\_index).\n",
        "\n",
        "**Limitations**\n",
        "\n",
        "* **Traceability:** No hash of source docs; reproducibility depends on environment.\n",
        "* **Versioning:** Model/version not recorded; difficulty tagger method not recorded.\n",
        "\n",
        "**Improvements**\n",
        "\n",
        "* Add a header block:\n",
        "\n",
        "  * `source_documents`: \\[{path, sha256}]\n",
        "  * `models`: generation/verifier/embedding names & versions\n",
        "  * `run_config`: chunk sizes, stride, budgets, timestamps, seed\n",
        "  * `metrics`: {before/after dedup, pass rates, difficulty distribution, tokens, cost}\n",
        "\n",
        "**Acceptance checks**\n",
        "\n",
        "* Re-running with same inputs & seed yields ‚â•95% identical questions (modulo nondeterminism).\n",
        "\n",
        "---\n",
        "\n",
        "## 8) Human-in-the-Loop (optional but powerful)\n",
        "\n",
        "**What‚Äôs good:** Fully automated baseline.\n",
        "\n",
        "**Limitations**\n",
        "\n",
        "* Some borderline items will slip through any automatic filter.\n",
        "\n",
        "**Improvements**\n",
        "\n",
        "* Add a compact review UI (streamlit/notebook table):\n",
        "\n",
        "  * Columns: question, choices, correct, evidence\\_span, difficulty, score, flags.\n",
        "  * Reviewer actions: approve / edit / reject.\n",
        "* Persist reviewer decisions to a small SQLite/CSV ‚Äúaudit log.‚Äù\n",
        "\n",
        "**Acceptance checks**\n",
        "\n",
        "* Reviewer can triage \\~50 items in ‚â§10 minutes; export only approved items if ‚ÄúHITL‚Äù mode is on.\n",
        "\n",
        "---\n",
        "\n",
        "## 9) Model Choice Justification\n",
        "\n",
        "> We selected **GPT-4o-mini** for its speed and cost efficiency during development."
      ],
      "metadata": {
        "id": "QoOcXOJEdnQ5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Final Fully Improved Pipeline"
      ],
      "metadata": {
        "id": "QUwy6GxNfywy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pymupdf pdfplumber ftfy openai tiktoken numpy pandas scikit-learn\n",
        "!pip install nest_asyncio"
      ],
      "metadata": {
        "id": "oJFDq5NhicyD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nest_asyncio, asyncio\n",
        "nest_asyncio.apply()"
      ],
      "metadata": {
        "id": "V6xO4DsnjDm5"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "paths = [\n",
        "    \"/content/notes.pdf\",\n",
        "    \"/content/transcript_1.txt\",\n",
        "    \"/content/transcript_2.txt\",\n",
        "    \"/content/transcript_3.txt\",\n",
        "    \"/content/transcript_4.txt\",\n",
        "    \"/content/transcript_5.txt\",\n",
        "]"
      ],
      "metadata": {
        "id": "7Nk7rAmTifxJ"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sota_mcq_pipeline import RunConfig, _run_async\n",
        "\n",
        "cfg = RunConfig(\n",
        "    n_questions_per_chunk=2,   # target ~150 MCQs\n",
        "    max_chunks=None,           # process ALL chunks\n",
        "    dedup_llm_confirm=False,   # faster, good enough for assignment\n",
        ")"
      ],
      "metadata": {
        "id": "d92znpPqr1tb"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Monkey-patch JSON to handle numpy types\n",
        "import numpy as np\n",
        "\n",
        "def json_dump_with_numpy(obj, f, **kwargs):\n",
        "    def default(o):\n",
        "        if isinstance(o, (np.integer,)): return int(o)\n",
        "        if isinstance(o, (np.floating,)): return float(o)\n",
        "        if isinstance(o, (np.ndarray,)): return o.tolist()\n",
        "        raise TypeError(f\"Object of type {o.__class__.__name__} is not JSON serializable\")\n",
        "    return json._orig_dump(obj, f, default=default, **kwargs)\n",
        "\n",
        "if not hasattr(json, \"_orig_dump\"):\n",
        "    json._orig_dump = json.dump\n",
        "json.dump = json_dump_with_numpy"
      ],
      "metadata": {
        "id": "hRC7SWkzsxWt"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run async pipeline on ALL chunks\n",
        "res = await _run_async(paths, out_path=\"/content/questions_sota.json\", cfg=cfg)\n",
        "\n",
        "# Restore json.dump (optional)\n",
        "json.dump = json._orig_dump\n",
        "\n",
        "# Quick stats\n",
        "print(\"‚úÖ Done\")\n",
        "print(\"Counts:\", res[\"counts\"])\n",
        "print(\"Difficulty distribution:\", res[\"difficulty_distribution\"])\n",
        "print(\"Runtime (sec):\", res[\"runtime_seconds\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NpgHi50gs0Q_",
        "outputId": "f8646ca6-a230-4e18-ed59-bf70b184b5f7"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Done\n",
            "Counts: {'documents': 6, 'chunks': 254, 'generated': 496, 'answerability_failed': 16, 'after_dedup': 468}\n",
            "Difficulty distribution: {'easy': np.int64(353), 'medium': np.int64(105), 'hard': np.int64(10)}\n",
            "Runtime (sec): 2.35\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random, json\n",
        "from collections import defaultdict\n",
        "\n",
        "# Group questions by difficulty\n",
        "by_diff = defaultdict(list)\n",
        "for q in res[\"questions\"]:\n",
        "    by_diff[q[\"difficulty\"]].append(q)\n",
        "\n",
        "# Desired proportions (adjust as needed)\n",
        "target_total = 150\n",
        "ratios = {\"easy\": 0.6, \"medium\": 0.3, \"hard\": 0.1}\n",
        "target_counts = {k: int(target_total * v) for k, v in ratios.items()}\n",
        "\n",
        "# Ensure we don‚Äôt request more than available\n",
        "for k in target_counts:\n",
        "    target_counts[k] = min(target_counts[k], len(by_diff.get(k, [])))\n",
        "\n",
        "# Sample\n",
        "selected = []\n",
        "for diff, qs in by_diff.items():\n",
        "    n = target_counts.get(diff, 0)\n",
        "    if n > 0 and len(qs) >= n:\n",
        "        selected.extend(random.sample(qs, n))\n",
        "    elif n > 0:  # if fewer available than needed, take all\n",
        "        selected.extend(qs)\n",
        "\n",
        "# If total < target (because hard had too few), top up from easy/medium\n",
        "while len(selected) < target_total:\n",
        "    pool = by_diff[\"easy\"] + by_diff[\"medium\"]\n",
        "    extra = random.choice(pool)\n",
        "    if extra not in selected:\n",
        "        selected.append(extra)\n",
        "\n",
        "# Save final balanced file\n",
        "with open(\"/content/questions_sota_150.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(selected, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "print(\"‚úÖ Stratified file created with\", len(selected), \"questions\")\n",
        "print(\"Final distribution:\", {d: sum(1 for q in selected if q[\"difficulty\"]==d) for d in [\"easy\",\"medium\",\"hard\"]})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i4IfcwHUs25c",
        "outputId": "d0aab21d-82a4-4315-f302-137b37eed80a"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Stratified file created with 150 questions\n",
            "Final distribution: {'easy': 94, 'medium': 46, 'hard': 10}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip freeze > requirements.txt"
      ],
      "metadata": {
        "id": "6WdnUxf50pJ4"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cat /content/requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zAn4jfgX0uQz",
        "outputId": "81fc34b5-1a86-4850-a5f0-68d2abfb9dd6"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "absl-py==1.4.0\n",
            "absolufy-imports==0.3.1\n",
            "accelerate==1.10.1\n",
            "aiofiles==24.1.0\n",
            "aiohappyeyeballs==2.6.1\n",
            "aiohttp==3.12.15\n",
            "aiosignal==1.4.0\n",
            "alabaster==1.0.0\n",
            "albucore==0.0.24\n",
            "albumentations==2.0.8\n",
            "ale-py==0.11.2\n",
            "alembic==1.16.5\n",
            "altair==5.5.0\n",
            "annotated-types==0.7.0\n",
            "antlr4-python3-runtime==4.9.3\n",
            "anyio==4.10.0\n",
            "anywidget==0.9.18\n",
            "argon2-cffi==25.1.0\n",
            "argon2-cffi-bindings==25.1.0\n",
            "array_record==0.8.1\n",
            "arrow==1.3.0\n",
            "arviz==0.22.0\n",
            "astropy==7.1.0\n",
            "astropy-iers-data==0.2025.9.1.0.42.11\n",
            "astunparse==1.6.3\n",
            "atpublic==5.1\n",
            "attrs==25.3.0\n",
            "audioread==3.0.1\n",
            "Authlib==1.6.3\n",
            "autograd==1.8.0\n",
            "babel==2.17.0\n",
            "backcall==0.2.0\n",
            "beartype==0.21.0\n",
            "beautifulsoup4==4.13.5\n",
            "betterproto==2.0.0b6\n",
            "bigframes==2.18.0\n",
            "bigquery-magics==0.10.3\n",
            "bleach==6.2.0\n",
            "blinker==1.9.0\n",
            "blis==1.3.0\n",
            "blobfile==3.0.0\n",
            "blosc2==3.7.2\n",
            "bokeh==3.7.3\n",
            "Bottleneck==1.4.2\n",
            "bqplot==0.12.45\n",
            "branca==0.8.1\n",
            "Brotli==1.1.0\n",
            "build==1.3.0\n",
            "CacheControl==0.14.3\n",
            "cachetools==5.5.2\n",
            "catalogue==2.0.10\n",
            "certifi==2025.8.3\n",
            "cffi==1.17.1\n",
            "chardet==5.2.0\n",
            "charset-normalizer==3.4.3\n",
            "chex==0.1.90\n",
            "clarabel==0.11.1\n",
            "click==8.2.1\n",
            "cloudpathlib==0.22.0\n",
            "cloudpickle==3.1.1\n",
            "cmake==3.31.6\n",
            "cmdstanpy==1.2.5\n",
            "colorcet==3.1.0\n",
            "colorlover==0.3.0\n",
            "colour==0.1.5\n",
            "community==1.0.0b1\n",
            "confection==0.1.5\n",
            "cons==0.4.7\n",
            "contourpy==1.3.3\n",
            "cramjam==2.11.0\n",
            "cryptography==43.0.3\n",
            "cuda-python==12.6.2.post1\n",
            "cudf-cu12 @ https://pypi.nvidia.com/cudf-cu12/cudf_cu12-25.6.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl\n",
            "cudf-polars-cu12==25.6.0\n",
            "cufflinks==0.17.3\n",
            "cuml-cu12==25.6.0\n",
            "cupy-cuda12x==13.3.0\n",
            "curl_cffi==0.13.0\n",
            "cuvs-cu12==25.6.1\n",
            "cvxopt==1.3.2\n",
            "cvxpy==1.6.7\n",
            "cycler==0.12.1\n",
            "cyipopt==1.5.0\n",
            "cymem==2.0.11\n",
            "Cython==3.0.12\n",
            "dask==2025.5.0\n",
            "dask-cuda==25.6.0\n",
            "dask-cudf-cu12==25.6.0\n",
            "dataproc-spark-connect==0.8.3\n",
            "datasets==4.0.0\n",
            "db-dtypes==1.4.3\n",
            "dbus-python==1.2.18\n",
            "debugpy==1.8.15\n",
            "decorator==4.4.2\n",
            "defusedxml==0.7.1\n",
            "diffusers==0.35.1\n",
            "dill==0.3.8\n",
            "distributed==2025.5.0\n",
            "distributed-ucxx-cu12==0.44.0\n",
            "distro==1.9.0\n",
            "dlib==19.24.6\n",
            "dm-tree==0.1.9\n",
            "docstring_parser==0.17.0\n",
            "docutils==0.21.2\n",
            "dopamine_rl==4.1.2\n",
            "duckdb==1.3.2\n",
            "earthengine-api==1.5.24\n",
            "easydict==1.13\n",
            "editdistance==0.8.1\n",
            "eerepr==0.1.2\n",
            "einops==0.8.1\n",
            "en_core_web_sm @ https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl#sha256=1932429db727d4bff3deed6b34cfc05df17794f4a52eeb26cf8928f7c1a0fb85\n",
            "entrypoints==0.4\n",
            "et_xmlfile==2.0.0\n",
            "etils==1.13.0\n",
            "etuples==0.3.10\n",
            "Farama-Notifications==0.0.4\n",
            "fastai==2.8.4\n",
            "fastapi==0.116.1\n",
            "fastcore==1.8.8\n",
            "fastdownload==0.0.7\n",
            "fastjsonschema==2.21.2\n",
            "fastprogress==1.0.3\n",
            "fastrlock==0.8.3\n",
            "fasttransform==0.0.2\n",
            "ffmpy==0.6.1\n",
            "filelock==3.19.1\n",
            "firebase-admin==6.9.0\n",
            "Flask==3.1.2\n",
            "flatbuffers==25.2.10\n",
            "flax==0.10.6\n",
            "folium==0.20.0\n",
            "fonttools==4.59.2\n",
            "fqdn==1.5.1\n",
            "frozendict==2.4.6\n",
            "frozenlist==1.7.0\n",
            "fsspec==2025.3.0\n",
            "ftfy==6.3.1\n",
            "future==1.0.0\n",
            "gast==0.6.0\n",
            "gcsfs==2025.3.0\n",
            "GDAL==3.8.4\n",
            "gdown==5.2.0\n",
            "geemap==0.35.3\n",
            "geocoder==1.38.1\n",
            "geographiclib==2.1\n",
            "geopandas==1.1.1\n",
            "geopy==2.4.1\n",
            "gin-config==0.5.0\n",
            "gitdb==4.0.12\n",
            "GitPython==3.1.45\n",
            "glob2==0.7\n",
            "google==2.0.3\n",
            "google-adk==1.13.0\n",
            "google-ai-generativelanguage==0.6.15\n",
            "google-api-core==2.25.1\n",
            "google-api-python-client==2.181.0\n",
            "google-auth==2.38.0\n",
            "google-auth-httplib2==0.2.0\n",
            "google-auth-oauthlib==1.2.2\n",
            "google-cloud-aiplatform==1.111.0\n",
            "google-cloud-appengine-logging==1.6.2\n",
            "google-cloud-audit-log==0.3.2\n",
            "google-cloud-bigquery==3.36.0\n",
            "google-cloud-bigquery-connection==1.18.3\n",
            "google-cloud-bigquery-storage==2.33.0\n",
            "google-cloud-bigtable==2.32.0\n",
            "google-cloud-core==2.4.3\n",
            "google-cloud-dataproc==5.21.0\n",
            "google-cloud-datastore==2.21.0\n",
            "google-cloud-firestore==2.21.0\n",
            "google-cloud-functions==1.20.4\n",
            "google-cloud-language==2.17.2\n",
            "google-cloud-logging==3.12.1\n",
            "google-cloud-resource-manager==1.14.2\n",
            "google-cloud-secret-manager==2.24.0\n",
            "google-cloud-spanner==3.57.0\n",
            "google-cloud-speech==2.33.0\n",
            "google-cloud-storage==2.19.0\n",
            "google-cloud-trace==1.16.2\n",
            "google-cloud-translate==3.21.1\n",
            "google-colab @ file:///colabtools/dist/google_colab-1.0.0.tar.gz\n",
            "google-crc32c==1.7.1\n",
            "google-genai==1.33.0\n",
            "google-generativeai==0.8.5\n",
            "google-pasta==0.2.0\n",
            "google-resumable-media==2.7.2\n",
            "googleapis-common-protos==1.70.0\n",
            "googledrivedownloader==1.1.0\n",
            "gradio==5.44.1\n",
            "gradio_client==1.12.1\n",
            "graphviz==0.21\n",
            "greenlet==3.2.4\n",
            "groovy==0.1.2\n",
            "grpc-google-iam-v1==0.14.2\n",
            "grpc-interceptor==0.15.4\n",
            "grpcio==1.74.0\n",
            "grpcio-status==1.71.2\n",
            "grpclib==0.4.8\n",
            "gspread==6.2.1\n",
            "gspread-dataframe==4.0.0\n",
            "gym==0.25.2\n",
            "gym-notices==0.1.0\n",
            "gymnasium==1.2.0\n",
            "h11==0.16.0\n",
            "h2==4.3.0\n",
            "h5netcdf==1.6.4\n",
            "h5py==3.14.0\n",
            "hdbscan==0.8.40\n",
            "hf-xet==1.1.9\n",
            "hf_transfer==0.1.9\n",
            "highspy==1.11.0\n",
            "holidays==0.80\n",
            "holoviews==1.21.0\n",
            "hpack==4.1.0\n",
            "html5lib==1.1\n",
            "httpcore==1.0.9\n",
            "httpimport==1.4.1\n",
            "httplib2==0.30.0\n",
            "httpx==0.28.1\n",
            "httpx-sse==0.4.1\n",
            "huggingface-hub==0.34.4\n",
            "humanize==4.13.0\n",
            "hyperframe==6.1.0\n",
            "hyperopt==0.2.7\n",
            "ibis-framework==9.5.0\n",
            "idna==3.10\n",
            "imageio==2.37.0\n",
            "imageio-ffmpeg==0.6.0\n",
            "imagesize==1.4.1\n",
            "imbalanced-learn==0.14.0\n",
            "immutabledict==4.2.1\n",
            "importlib_metadata==8.7.0\n",
            "importlib_resources==6.5.2\n",
            "imutils==0.5.4\n",
            "inflect==7.5.0\n",
            "iniconfig==2.1.0\n",
            "intel-cmplr-lib-ur==2025.2.1\n",
            "intel-openmp==2025.2.1\n",
            "ipyevents==2.0.2\n",
            "ipyfilechooser==0.6.0\n",
            "ipykernel==6.17.1\n",
            "ipyleaflet==0.20.0\n",
            "ipyparallel==8.8.0\n",
            "ipython==7.34.0\n",
            "ipython-genutils==0.2.0\n",
            "ipython-sql==0.5.0\n",
            "ipytree==0.2.2\n",
            "ipywidgets==7.7.1\n",
            "isoduration==20.11.0\n",
            "itsdangerous==2.2.0\n",
            "jaraco.classes==3.4.0\n",
            "jaraco.context==6.0.1\n",
            "jaraco.functools==4.3.0\n",
            "jax==0.5.3\n",
            "jax-cuda12-pjrt==0.5.3\n",
            "jax-cuda12-plugin==0.5.3\n",
            "jaxlib==0.5.3\n",
            "jeepney==0.9.0\n",
            "jieba==0.42.1\n",
            "Jinja2==3.1.6\n",
            "jiter==0.10.0\n",
            "joblib==1.5.2\n",
            "jsonpatch==1.33\n",
            "jsonpickle==4.1.1\n",
            "jsonpointer==3.0.0\n",
            "jsonschema==4.25.1\n",
            "jsonschema-specifications==2025.4.1\n",
            "jupyter-console==6.6.3\n",
            "jupyter-events==0.12.0\n",
            "jupyter-leaflet==0.20.0\n",
            "jupyter_client==7.4.9\n",
            "jupyter_core==5.8.1\n",
            "jupyter_kernel_gateway @ git+https://github.com/googlecolab/kernel_gateway@b134e9945df25c2dcb98ade9129399be10788671\n",
            "jupyter_server==2.14.0\n",
            "jupyter_server_terminals==0.5.3\n",
            "jupyterlab_pygments==0.3.0\n",
            "jupyterlab_widgets==3.0.15\n",
            "jupytext==1.17.3\n",
            "kaggle==1.7.4.5\n",
            "kagglehub==0.3.13\n",
            "keras==3.10.0\n",
            "keras-hub==0.21.1\n",
            "keras-nlp==0.21.1\n",
            "keyring==25.6.0\n",
            "keyrings.google-artifactregistry-auth==1.1.2\n",
            "kiwisolver==1.4.9\n",
            "langchain==0.3.27\n",
            "langchain-core==0.3.75\n",
            "langchain-text-splitters==0.3.11\n",
            "langcodes==3.5.0\n",
            "langsmith==0.4.24\n",
            "language_data==1.3.0\n",
            "lark==1.2.2\n",
            "launchpadlib==1.10.16\n",
            "lazr.restfulclient==0.14.4\n",
            "lazr.uri==1.0.6\n",
            "lazy_loader==0.4\n",
            "libclang==18.1.1\n",
            "libcudf-cu12 @ https://pypi.nvidia.com/libcudf-cu12/libcudf_cu12-25.6.0-py3-none-manylinux_2_28_x86_64.whl\n",
            "libcugraph-cu12==25.6.0\n",
            "libcuml-cu12==25.6.0\n",
            "libcuvs-cu12==25.6.1\n",
            "libkvikio-cu12==25.6.0\n",
            "libpysal==4.13.0\n",
            "libraft-cu12==25.6.0\n",
            "librmm-cu12==25.6.0\n",
            "librosa==0.11.0\n",
            "libucx-cu12==1.18.1\n",
            "libucxx-cu12==0.44.0\n",
            "lightgbm @ file:///tmp/lightgbm/LightGBM/dist/lightgbm-4.6.0-py3-none-linux_x86_64.whl\n",
            "linkify-it-py==2.0.3\n",
            "llvmlite==0.43.0\n",
            "locket==1.0.0\n",
            "logical-unification==0.4.6\n",
            "lxml==5.4.0\n",
            "Mako==1.3.10\n",
            "marisa-trie==1.3.1\n",
            "Markdown==3.9\n",
            "markdown-it-py==4.0.0\n",
            "MarkupSafe==3.0.2\n",
            "matplotlib==3.10.0\n",
            "matplotlib-inline==0.1.7\n",
            "matplotlib-venn==1.1.2\n",
            "mcp==1.13.1\n",
            "mdit-py-plugins==0.5.0\n",
            "mdurl==0.1.2\n",
            "miniKanren==1.0.5\n",
            "missingno==0.5.2\n",
            "mistune==3.1.4\n",
            "mizani==0.13.5\n",
            "mkl==2025.2.0\n",
            "ml_dtypes==0.5.3\n",
            "mlxtend==0.23.4\n",
            "more-itertools==10.8.0\n",
            "moviepy==1.0.3\n",
            "mpmath==1.3.0\n",
            "msgpack==1.1.1\n",
            "multidict==6.6.4\n",
            "multipledispatch==1.0.0\n",
            "multiprocess==0.70.16\n",
            "multitasking==0.0.12\n",
            "murmurhash==1.0.13\n",
            "music21==9.3.0\n",
            "namex==0.1.0\n",
            "narwhals==2.3.0\n",
            "natsort==8.4.0\n",
            "nbclassic==1.3.2\n",
            "nbclient==0.10.2\n",
            "nbconvert==7.16.6\n",
            "nbformat==5.10.4\n",
            "ndindex==1.10.0\n",
            "nest-asyncio==1.6.0\n",
            "networkx==3.5\n",
            "nibabel==5.3.2\n",
            "nltk==3.9.1\n",
            "notebook==6.5.7\n",
            "notebook_shim==0.2.4\n",
            "numba==0.60.0\n",
            "numba-cuda==0.11.0\n",
            "numexpr==2.11.0\n",
            "numpy==2.0.2\n",
            "nvidia-cublas-cu12==12.6.4.1\n",
            "nvidia-cuda-cupti-cu12==12.6.80\n",
            "nvidia-cuda-nvcc-cu12==12.5.82\n",
            "nvidia-cuda-nvrtc-cu12==12.6.77\n",
            "nvidia-cuda-runtime-cu12==12.6.77\n",
            "nvidia-cudnn-cu12==9.10.2.21\n",
            "nvidia-cufft-cu12==11.3.0.4\n",
            "nvidia-cufile-cu12==1.11.1.6\n",
            "nvidia-curand-cu12==10.3.7.77\n",
            "nvidia-cusolver-cu12==11.7.1.2\n",
            "nvidia-cusparse-cu12==12.5.4.2\n",
            "nvidia-cusparselt-cu12==0.7.1\n",
            "nvidia-ml-py==12.575.51\n",
            "nvidia-nccl-cu12==2.27.3\n",
            "nvidia-nvjitlink-cu12==12.6.85\n",
            "nvidia-nvtx-cu12==12.6.77\n",
            "nvtx==0.2.13\n",
            "nx-cugraph-cu12 @ https://pypi.nvidia.com/nx-cugraph-cu12/nx_cugraph_cu12-25.6.0-py3-none-any.whl\n",
            "oauth2client==4.1.3\n",
            "oauthlib==3.3.1\n",
            "omegaconf==2.3.0\n",
            "openai==1.106.1\n",
            "opencv-contrib-python==4.12.0.88\n",
            "opencv-python==4.12.0.88\n",
            "opencv-python-headless==4.12.0.88\n",
            "openpyxl==3.1.5\n",
            "opentelemetry-api==1.36.0\n",
            "opentelemetry-exporter-gcp-trace==1.9.0\n",
            "opentelemetry-resourcedetector-gcp==1.9.0a0\n",
            "opentelemetry-sdk==1.36.0\n",
            "opentelemetry-semantic-conventions==0.57b0\n",
            "opt_einsum==3.4.0\n",
            "optax==0.2.5\n",
            "optree==0.17.0\n",
            "orbax-checkpoint==0.11.24\n",
            "orjson==3.11.3\n",
            "osqp==1.0.4\n",
            "overrides==7.7.0\n",
            "packaging==25.0\n",
            "pandas==2.2.2\n",
            "pandas-datareader==0.10.0\n",
            "pandas-gbq==0.29.2\n",
            "pandas-stubs==2.2.2.240909\n",
            "pandocfilters==1.5.1\n",
            "panel==1.7.5\n",
            "param==2.2.1\n",
            "parso==0.8.5\n",
            "parsy==2.1\n",
            "partd==1.4.2\n",
            "patsy==1.0.1\n",
            "pdfminer.six==20250506\n",
            "pdfplumber==0.11.7\n",
            "peewee==3.18.2\n",
            "peft==0.17.1\n",
            "pexpect==4.9.0\n",
            "pickleshare==0.7.5\n",
            "pillow==11.3.0\n",
            "platformdirs==4.4.0\n",
            "plotly==5.24.1\n",
            "plotnine==0.14.5\n",
            "pluggy==1.6.0\n",
            "plum-dispatch==2.5.7\n",
            "ply==3.11\n",
            "polars==1.25.2\n",
            "pooch==1.8.2\n",
            "portpicker==1.5.2\n",
            "preshed==3.0.10\n",
            "prettytable==3.16.0\n",
            "proglog==0.1.12\n",
            "progressbar2==4.5.0\n",
            "prometheus_client==0.22.1\n",
            "promise==2.3\n",
            "prompt_toolkit==3.0.52\n",
            "propcache==0.3.2\n",
            "prophet==1.1.7\n",
            "proto-plus==1.26.1\n",
            "protobuf==5.29.5\n",
            "psutil==5.9.5\n",
            "psycopg2==2.9.10\n",
            "psygnal==0.14.1\n",
            "ptyprocess==0.7.0\n",
            "py-cpuinfo==9.0.0\n",
            "py4j==0.10.9.7\n",
            "pyarrow==18.1.0\n",
            "pyasn1==0.6.1\n",
            "pyasn1_modules==0.4.2\n",
            "pycairo==1.28.0\n",
            "pycocotools==2.0.10\n",
            "pycparser==2.22\n",
            "pycryptodomex==3.23.0\n",
            "pydantic==2.11.7\n",
            "pydantic-settings==2.10.1\n",
            "pydantic_core==2.33.2\n",
            "pydata-google-auth==1.9.1\n",
            "pydot==3.0.4\n",
            "pydotplus==2.0.2\n",
            "PyDrive2==1.21.3\n",
            "pydub==0.25.1\n",
            "pyerfa==2.0.1.5\n",
            "pygame==2.6.1\n",
            "pygit2==1.18.2\n",
            "Pygments==2.19.2\n",
            "PyGObject==3.42.0\n",
            "PyJWT==2.10.1\n",
            "pylibcudf-cu12 @ https://pypi.nvidia.com/pylibcudf-cu12/pylibcudf_cu12-25.6.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl\n",
            "pylibcugraph-cu12==25.6.0\n",
            "pylibraft-cu12==25.6.0\n",
            "pymc==5.25.1\n",
            "PyMuPDF==1.26.4\n",
            "pynndescent==0.5.13\n",
            "pynvjitlink-cu12==0.7.0\n",
            "pynvml==12.0.0\n",
            "pyogrio==0.11.1\n",
            "pyomo==6.9.4\n",
            "PyOpenGL==3.1.10\n",
            "pyOpenSSL==24.2.1\n",
            "pyparsing==3.2.3\n",
            "pypdfium2==4.30.0\n",
            "pyperclip==1.9.0\n",
            "pyproj==3.7.2\n",
            "pyproject_hooks==1.2.0\n",
            "pyshp==2.3.1\n",
            "PySocks==1.7.1\n",
            "pyspark==3.5.1\n",
            "pytensor==2.31.7\n",
            "pytest==8.4.2\n",
            "python-apt==0.0.0\n",
            "python-box==7.3.2\n",
            "python-dateutil==2.9.0.post0\n",
            "python-dotenv==1.1.1\n",
            "python-json-logger==3.3.0\n",
            "python-louvain==0.16\n",
            "python-multipart==0.0.20\n",
            "python-slugify==8.0.4\n",
            "python-snappy==0.7.3\n",
            "python-utils==3.9.1\n",
            "pytz==2025.2\n",
            "pyviz_comms==3.0.6\n",
            "PyWavelets==1.9.0\n",
            "PyYAML==6.0.2\n",
            "pyzmq==26.2.1\n",
            "raft-dask-cu12==25.6.0\n",
            "rapids-dask-dependency==25.6.0\n",
            "rapids-logger==0.1.1\n",
            "ratelim==0.1.6\n",
            "referencing==0.36.2\n",
            "regex==2024.11.6\n",
            "requests==2.32.4\n",
            "requests-oauthlib==2.0.0\n",
            "requests-toolbelt==1.0.0\n",
            "requirements-parser==0.9.0\n",
            "rfc3339-validator==0.1.4\n",
            "rfc3986-validator==0.1.1\n",
            "rfc3987-syntax==1.1.0\n",
            "rich==13.9.4\n",
            "rmm-cu12==25.6.0\n",
            "roman-numerals-py==3.1.0\n",
            "rpds-py==0.27.1\n",
            "rpy2==3.5.17\n",
            "rsa==4.9.1\n",
            "ruff==0.12.12\n",
            "safehttpx==0.1.6\n",
            "safetensors==0.6.2\n",
            "scikit-image==0.25.2\n",
            "scikit-learn==1.6.1\n",
            "scipy==1.16.1\n",
            "scooby==0.10.1\n",
            "scs==3.2.8\n",
            "seaborn==0.13.2\n",
            "SecretStorage==3.3.3\n",
            "semantic-version==2.10.0\n",
            "Send2Trash==1.8.3\n",
            "sentence-transformers==5.1.0\n",
            "sentencepiece==0.2.1\n",
            "sentry-sdk==2.36.0\n",
            "setuptools==75.2.0\n",
            "shap==0.48.0\n",
            "shapely==2.1.1\n",
            "shellingham==1.5.4\n",
            "simple-parsing==0.1.7\n",
            "simplejson==3.20.1\n",
            "simsimd==6.5.1\n",
            "six==1.17.0\n",
            "sklearn-pandas==2.2.0\n",
            "slicer==0.0.8\n",
            "smart_open==7.3.0.post1\n",
            "smmap==5.0.2\n",
            "sniffio==1.3.1\n",
            "snowballstemmer==3.0.1\n",
            "sortedcontainers==2.4.0\n",
            "soundfile==0.13.1\n",
            "soupsieve==2.8\n",
            "soxr==0.5.0.post1\n",
            "spacy==3.8.7\n",
            "spacy-legacy==3.0.12\n",
            "spacy-loggers==1.0.5\n",
            "spanner-graph-notebook==1.1.8\n",
            "Sphinx==8.2.3\n",
            "sphinxcontrib-applehelp==2.0.0\n",
            "sphinxcontrib-devhelp==2.0.0\n",
            "sphinxcontrib-htmlhelp==2.1.0\n",
            "sphinxcontrib-jsmath==1.0.1\n",
            "sphinxcontrib-qthelp==2.0.0\n",
            "sphinxcontrib-serializinghtml==2.0.0\n",
            "SQLAlchemy==2.0.43\n",
            "sqlalchemy-spanner==1.16.0\n",
            "sqlglot==25.20.2\n",
            "sqlparse==0.5.3\n",
            "srsly==2.5.1\n",
            "sse-starlette==3.0.2\n",
            "stanio==0.5.1\n",
            "starlette==0.47.3\n",
            "statsmodels==0.14.5\n",
            "stringzilla==3.12.6\n",
            "stumpy==1.13.0\n",
            "sympy==1.13.3\n",
            "tables==3.10.2\n",
            "tabulate==0.9.0\n",
            "tbb==2022.2.0\n",
            "tblib==3.1.0\n",
            "tcmlib==1.4.0\n",
            "tenacity==8.5.0\n",
            "tensorboard==2.19.0\n",
            "tensorboard-data-server==0.7.2\n",
            "tensorflow==2.19.0\n",
            "tensorflow-datasets==4.9.9\n",
            "tensorflow-hub==0.16.1\n",
            "tensorflow-metadata==1.17.2\n",
            "tensorflow-probability==0.25.0\n",
            "tensorflow-text==2.19.0\n",
            "tensorflow_decision_forests==1.12.0\n",
            "tensorstore==0.1.76\n",
            "termcolor==3.1.0\n",
            "terminado==0.18.1\n",
            "text-unidecode==1.3\n",
            "textblob==0.19.0\n",
            "tf-slim==1.1.0\n",
            "tf_keras==2.19.0\n",
            "thinc==8.3.6\n",
            "threadpoolctl==3.6.0\n",
            "tifffile==2025.8.28\n",
            "tiktoken==0.11.0\n",
            "timm==1.0.19\n",
            "tinycss2==1.4.0\n",
            "tokenizers==0.22.0\n",
            "toml==0.10.2\n",
            "tomlkit==0.13.3\n",
            "toolz==0.12.1\n",
            "torch==2.8.0+cu126\n",
            "torchao==0.10.0\n",
            "torchaudio==2.8.0+cu126\n",
            "torchdata==0.11.0\n",
            "torchsummary==1.5.1\n",
            "torchtune==0.6.1\n",
            "torchvision==0.23.0+cu126\n",
            "tornado==6.4.2\n",
            "tqdm==4.67.1\n",
            "traitlets==5.7.1\n",
            "traittypes==0.2.1\n",
            "transformers==4.56.1\n",
            "treelite==4.4.1\n",
            "treescope==0.1.10\n",
            "triton==3.4.0\n",
            "tsfresh==0.21.1\n",
            "tweepy==4.16.0\n",
            "typeguard==4.4.4\n",
            "typer==0.17.3\n",
            "types-python-dateutil==2.9.0.20250822\n",
            "types-pytz==2025.2.0.20250809\n",
            "types-setuptools==80.9.0.20250822\n",
            "typing-inspection==0.4.1\n",
            "typing_extensions==4.15.0\n",
            "tzdata==2025.2\n",
            "tzlocal==5.3.1\n",
            "uc-micro-py==1.0.3\n",
            "ucx-py-cu12==0.44.0\n",
            "ucxx-cu12==0.44.0\n",
            "umap-learn==0.5.9.post2\n",
            "umf==0.11.0\n",
            "uri-template==1.3.0\n",
            "uritemplate==4.2.0\n",
            "urllib3==2.5.0\n",
            "uvicorn==0.35.0\n",
            "vega-datasets==0.9.0\n",
            "wadllib==1.3.6\n",
            "wandb==0.21.3\n",
            "wasabi==1.1.3\n",
            "watchdog==6.0.0\n",
            "wcwidth==0.2.13\n",
            "weasel==0.4.1\n",
            "webcolors==24.11.1\n",
            "webencodings==0.5.1\n",
            "websocket-client==1.8.0\n",
            "websockets==15.0.1\n",
            "Werkzeug==3.1.3\n",
            "wheel==0.45.1\n",
            "widgetsnbextension==3.6.10\n",
            "wordcloud==1.9.4\n",
            "wrapt==1.17.3\n",
            "wurlitzer==3.1.1\n",
            "xarray==2025.9.0\n",
            "xarray-einstats==0.9.1\n",
            "xgboost==3.0.4\n",
            "xlrd==2.0.2\n",
            "xxhash==3.5.0\n",
            "xyzservices==2025.4.0\n",
            "yarl==1.20.1\n",
            "ydf==0.13.0\n",
            "yellowbrick==1.5\n",
            "yfinance==0.2.65\n",
            "zict==3.0.0\n",
            "zipp==3.23.0\n",
            "zstandard==0.24.0\n"
          ]
        }
      ]
    }
  ]
}